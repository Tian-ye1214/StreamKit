import streamlit as st
from openai import OpenAI
from pages.Functions.ExtractFileContents import encode_image_to_base64
from pages.Functions.BackendInteraction import (
    UserInteraction,
    ParameterConfiguration,
    get_system_prompt,
    initialize_session_state
)
from pages.Functions.Constants import (
    VISIONMODAL_MAPPING,
    SEARCH_METHODS,
)
from pages.Functions.WebSearch import WebSearch
import io


def main():
    initialize_session_state()
    st.session_state.openai_client = OpenAI(api_key=st.session_state.api_key, base_url=st.session_state.base_url)

    st.markdown("""
    <h1 style='text-align: center;'>
        Multimodal Chat
    </h1>
    <div style='text-align: center; margin-bottom: 20px;'>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        UserInteraction()
        st.markdown("""
        <h3 style='text-align: center;'>
            æ¨¡å‹é…ç½®
        </h3>
        """, unsafe_allow_html=True)

        if st.button("å¼€å¯æ–°å¯¹è¯", help="å¼€å¯æ–°å¯¹è¯å°†æ¸…ç©ºå½“å‰å¯¹è¯è®°å½•"):
            st.session_state.current_log_filename = None
            st.session_state.chat_messages = []
            st.success("å·²æˆåŠŸå¼€å¯æ–°çš„å¯¹è¯")
            st.rerun()

        model_display = st.selectbox("é€‰æ‹©æ¨¡å‹", list(VISIONMODAL_MAPPING.keys()), index=1, help="é€‰æ‹©æ¨¡å‹")
        model = VISIONMODAL_MAPPING[model_display]

        if model == "deepseek-ai/Janus-Pro-1B":
            st.session_state.janus_mode = st.radio(
                "å·¥ä½œæ¨¡å¼",
                ["å›¾ç‰‡ç†è§£æ¨¡å¼", "å›¾ç‰‡ç”Ÿæˆæ¨¡å¼"],
                index=0,
                horizontal=True,
                help="é€‰æ‹©Janusæ¨¡å‹çš„å·¥ä½œæ¨¡å¼"
            )

        ParameterConfiguration()

    with st.expander("å›¾ç‰‡ä¸Šä¼ ", expanded=False):
        uploaded_image = st.file_uploader(
            "ä¸Šä¼ å›¾ç‰‡",
            type=["jpg", "jpeg", "png"]
        )
        if uploaded_image:
            st.image(uploaded_image, caption="å›¾ç‰‡é¢„è§ˆ", use_container_width=True)

    with st.expander("ç”Ÿæˆå›¾ç‰‡æ“ä½œ", expanded=False):
        if 'generated_images' in st.session_state:
            st.markdown("### ç”Ÿæˆå›¾ç‰‡é¢„è§ˆ")
            cols = st.columns(3)
            for idx, img in enumerate(st.session_state.generated_images):
                with cols[idx % 3]:
                    st.image(img, use_container_width=True)
                    # åˆ›å»ºä¸‹è½½æŒ‰é’®
                    buf = io.BytesIO()
                    img.save(buf, format="PNG")
                    byte_im = buf.getvalue()
                    st.download_button(
                        label=f"ä¸‹è½½å›¾ç‰‡ {idx+1}",
                        data=byte_im,
                        file_name=f"generated_image_{idx+1}.png",
                        mime="image/png",
                        key=f"download_{idx}"
                    )
            
            # æ¸…ç©ºæŒ‰é’®
            if st.button("æ¸…ç©ºæ‰€æœ‰ç”Ÿæˆå›¾ç‰‡"):
                del st.session_state.generated_images
                st.rerun()
        else:
            st.info("æš‚æ— ç”Ÿæˆå›¾ç‰‡")

    msg_counter = st.empty()
    msg_counter.markdown(f"""
    <div style='text-align: center; margin: 10px 0; font-size:14px;'>
        å½“å‰å¯¹è¯æ¶ˆæ¯æ•°ï¼š<span style='color: #ff4b4b; font-weight:bold;'>{len(st.session_state.chat_messages)}</span>/40
    </div>
    """, unsafe_allow_html=True)

    for message in st.session_state.chat_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜ï¼š"):
        current_prompt = {"role": "user", "content": prompt}
        st.session_state.chat_messages.append(current_prompt)
        msg_counter.markdown(f"""
        <div style='text-align: center; margin: 10px 0; font-size:14px;'>
            å½“å‰å¯¹è¯æ¶ˆæ¯æ•°ï¼š<span style='color: #ff4b4b; font-weight:bold;'>{len(st.session_state.chat_messages)}</span>/40
        </div>
        """, unsafe_allow_html=True)

        with st.chat_message("user"):
            st.markdown(prompt)

        if st.session_state.search_mode in SEARCH_METHODS:
            try:
                search = WebSearch(query=prompt, max_results=st.session_state.search_max_results)
                method = getattr(search, SEARCH_METHODS[st.session_state.search_mode])
                st.session_state.search_result = method()

                # æ˜¾ç¤ºæœç´¢ç»“æœ
                with st.chat_message("assistant"):
                    st.markdown("ğŸ” æœç´¢åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š")
                    for i, result in enumerate(st.session_state.search_result):
                        st.markdown(f"{i + 1}. [{result['title']}]({result['href']})")
                        st.caption(result['body'][:min(len(result['body']), 100)] + "...")
            except Exception as e:
                st.error(f"æ²¡æœ‰æ£€ç´¢åˆ°ç­”æ¡ˆå“¦ï¼Œé”™è¯¯ä¿¡æ¯:{e}")
                st.session_state.search_result = None

        # AIå“åº”
        with st.chat_message("assistant"):
            try:
                if model == "deepseek-ai/Janus-Pro-1B":
                    if st.session_state.get('janus_mode', None) == "å›¾ç‰‡ç†è§£æ¨¡å¼" and uploaded_image:
                        if uploaded_image:
                            from pages.Functions.MmConversion import mmconversion
                            assistant_response = mmconversion(model, uploaded_image, prompt)
                            st.markdown(assistant_response)
                        else:
                            st.error("è¯·å…ˆä¸Šä¼ å›¾ç‰‡ï¼")
                            return
                    elif st.session_state.get('janus_mode', None) == "å›¾ç‰‡ç”Ÿæˆæ¨¡å¼":
                        from pages.Functions.MmGenerator import mmgeneration
                        generated_images = mmgeneration(model, prompt)
                        if generated_images:
                            st.session_state.generated_images = generated_images  # å­˜å‚¨ç”Ÿæˆçš„å›¾ç‰‡
                            st.rerun()  # è§¦å‘é¡µé¢åˆ·æ–°ä»¥æ˜¾ç¤ºå›¾ç‰‡
                else:
                    messages = [{"role": "system", "content": get_system_prompt()}]
                    base64_image = encode_image_to_base64(uploaded_image) if uploaded_image else None
                    if base64_image:
                        messages.append({
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}},
                            ],
                        })
                    else:
                        messages.append({"role": "user", "content": prompt})
                    messages.extend(
                        [{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_messages])
                    if st.session_state.stream:
                        reason_placeholder = st.empty()
                        message_placeholder = st.empty()
                        content = ""
                        reasoning_content = ""

                        for chunk in st.session_state.openai_client.chat.completions.create(
                                model=model,
                                messages=messages,
                                temperature=st.session_state.temperature,
                                top_p=st.session_state.top_p,
                                presence_penalty=st.session_state.presence_penalty,
                                frequency_penalty=st.session_state.frequency_penalty,
                                max_tokens=st.session_state.max_tokens,
                                stream=True
                        ):
                            if chunk.choices and len(chunk.choices) > 0:
                                delta = chunk.choices[0].delta
                                if getattr(delta, 'reasoning_content', None):
                                    reasoning_content += delta.reasoning_content
                                    reason_placeholder.markdown(
                                        f"<div style='background:#f0f0f0; border-radius:5px; padding:10px; margin-bottom:10px; font-size:14px;'>"
                                        f"ğŸ¤” {reasoning_content}</div>",
                                        unsafe_allow_html=True
                                    )
                                if delta and delta.content is not None:
                                    content += delta.content
                                    message_placeholder.markdown(
                                        f"<div style='font-size:16px; margin-top:10px;'>{content}</div>",
                                        unsafe_allow_html=True
                                    )
                        assistant_response = content
                    else:
                        response = st.session_state.openai_client.chat.completions.create(
                            model=model,
                            messages=messages,
                            temperature=st.session_state.temperature,
                            top_p=st.session_state.top_p,
                            presence_penalty=st.session_state.presence_penalty,
                            frequency_penalty=st.session_state.frequency_penalty,
                            max_tokens=st.session_state.max_tokens,
                            stream=False
                        )
                        reasoning_content = getattr(response.choices[0].message, 'reasoning_content', '')
                        assistant_response = response.choices[0].message.content

                        if reasoning_content:
                            st.markdown(
                                f"<div style='background:#f0f0f0; border-radius:5px; padding:10px; margin-bottom:10px; font-size:14px;'>"
                                f"ğŸ¤” {reasoning_content}</div>",
                                unsafe_allow_html=True
                            )
                        st.markdown(assistant_response)

                current_response = {"role": "assistant", "content": assistant_response}
                st.session_state.chat_messages.append(current_response)

                if len(st.session_state.chat_messages) > 40:
                    st.session_state.chat_messages = st.session_state.chat_messages[-40:]

                if st.session_state.current_user:
                    new_filename = st.session_state.log_manager.save_chat_log(
                        st.session_state.current_user,
                        [current_prompt, current_response],
                        log_filename=st.session_state.current_log_filename
                    )
                    if st.session_state.current_log_filename is None:
                        st.session_state.current_log_filename = new_filename

            except Exception as e:
                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}")


if __name__ == "__main__":
    main()
