import streamlit as st
import os
import re
from openai import OpenAI
import language_tool_python
from pages.Functions.Constants import HIGHSPEED_MODEL_MAPPING


def initialization():
    """
    åˆå§‹åŒ–å‡½æ•°ï¼šè®¾ç½®åº”ç”¨ç¨‹åºçš„åˆå§‹çŠ¶æ€
    ä½¿ç”¨Streamlitçš„session_stateæ¥å­˜å‚¨åº”ç”¨ç¨‹åºçš„çŠ¶æ€ä¿¡æ¯
    ä¿å­˜å†…å®¹ä¸ºæ“ä½œè®°å½•ã€çŠ¶æ€ä¿¡æ¯ã€è°ƒç”¨çš„LLMç­‰
    """
    if "Client" not in st.session_state:
        st.session_state.Client = OpenAI(api_key=os.environ.get('ZhiZz_API_KEY'), base_url=os.environ.get('ZhiZz_URL'))
    if "uploaded_file" not in st.session_state:
        st.session_state.uploaded_file = None
    if "TEX_content" not in st.session_state:
        st.session_state.TEX_content = None
    if "tex_history" not in st.session_state:
        st.session_state.tex_history = []
    if "tex_paragraphs" not in st.session_state:
        st.session_state.tex_paragraphs = []
    if "current_polishing_paragraph_index" not in st.session_state:
        st.session_state.current_polishing_paragraph_index = None
    if "show_all_paragraphs" not in st.session_state:
        st.session_state.show_all_paragraphs = True

    if "paragraph_to_polish" not in st.session_state:
        st.session_state.paragraph_to_polish = ""
    if "polishing_prompt" not in st.session_state:
        st.session_state.polishing_prompt = ("ä½ æ˜¯ä¸€ä½å­¦æœ¯è®ºæ–‡è¯„å®¡ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡è¯„å®¡ä¸‹è¿°æ–‡ç« æ®µè½ï¼Œå¹¶ï¼š"
                                             "1. ä¿®æ­£è¯­æ³•é”™è¯¯å’Œæ‹¼å†™é”™è¯¯ï¼› "
                                             "2. ä¼˜åŒ–å¥å¼ç»“æ„æå‡æµç•…æ€§ï¼› "
                                             "3. ç¡®ä¿ä¸“ä¸šæœ¯è¯­å‡†ç¡®ï¼› "
                                             "4. ç»´æŒå­¦æœ¯å†™ä½œè§„èŒƒã€‚è¯·ä¸¥æ ¼ç¡®ä¿è¾“å‡ºä»…åŒ…å«æ¶¦è‰²åçš„æ–‡æ®µï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€è¯´æ˜ã€æ³¨é‡Šç­‰å†…å®¹;"
                                             "5. ä¸è¦ä¿®æ”¹ä»»ä½•å¼•ç”¨ã€æ®µè½æ ‡è®°å†…å®¹ï¼Œå¦‚\\citeã€\\sectionã€‚"
                                             "6. ä¸è¦ä¿®æ”¹æ ¼å¼å†…å®¹ï¼Œå¦‚æ¢è¡Œã€ç¼©è¿›ã€ç©ºæ ¼ã€‚æ ¼å¼è¯·ä¸åŸæ–‡ä¿æŒä¸€è‡´"
                                             "ä¿®æ”¹è¿‡ç¨‹éœ€ä¿æŒåŸæ–‡æ ¸å¿ƒå«ä¹‰ä¸å˜ï¼Œä¸å¾—æ›´æ”¹ä¸“ä¸šæœ¯è¯­å’Œæ•°æ®ä¿¡æ¯ã€‚")
    if "polished_paragraph" not in st.session_state:
        st.session_state.polished_paragraph = None
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = "deepseek-chat"
    if "censorship_prompt" not in st.session_state:
        st.session_state.censorship_prompt = ("ä½ æ˜¯ä¸€ä½æ”¿æ²»å®¡æŸ¥ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯å¯¹ä¸‹è¿°æ–‡ç« è¿›è¡Œæ”¿æ²»å®¡æŸ¥ï¼Œå¹¶ï¼š"
                                             "1. è¯†åˆ«å¯èƒ½å­˜åœ¨çš„æ”¿æ²»æ•æ„Ÿå†…å®¹ï¼›"
                                             "2. è¯„ä¼°å†…å®¹çš„æ”¿æ²»å€¾å‘æ€§ï¼›"
                                             "3. æŒ‡å‡ºå¯èƒ½è¿åå›½å®¶æ³•å¾‹æ³•è§„çš„å†…å®¹ï¼›"
                                             "4. æä¾›è¯¦ç»†çš„å®¡æŸ¥æ„è§ã€‚")
    if "censorship_result" not in st.session_state:
        st.session_state.censorship_result = None
    if "current_censorship_paragraph_index" not in st.session_state:
        st.session_state.current_censorship_paragraph_index = None
    if "show_all_censorship_paragraphs" not in st.session_state:
        st.session_state.show_all_censorship_paragraphs = True
    if "paragraph_to_censor" not in st.session_state:
        st.session_state.paragraph_to_censor = ""
    if "censorship_results" not in st.session_state:
        st.session_state.censorship_results = {}


def polish_text_with_llm(text, prompt):
    """
    ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹å¯¹æ–‡æœ¬è¿›è¡Œæ¶¦è‰²
    
    å‚æ•°:
        text (str): éœ€è¦æ¶¦è‰²çš„æ–‡æœ¬å†…å®¹
        prompt (str): æ¶¦è‰²çš„æç¤ºè¯
    
    è¿”å›:
        str: æ¶¦è‰²åçš„æ–‡æœ¬å†…å®¹
    """
    # ç³»ç»Ÿæç¤ºè¯ï¼ŒæŒ‡å¯¼å¤§è¯­è¨€æ¨¡å‹çš„è¡Œä¸º
    system_prompt = """
    You are a professional academic writing optimization assistant specializing in refining and proofreading academic document excerpts. 
    Your core tasks are: 
    1. Correct grammatical errors and spelling mistakes 
    2. Optimize sentence structures for improved fluency 
    3. Ensure accurate usage of technical terminology 
    4. Maintain academic writing standards. Strictly provide ONLY the polished text without any explanations, notes, or additional comments. 
    5. Do not modify any citation or paragraph mark content, such as \\cite, \\section.
    6. Do not modify the formatting, such as line breaks, indents, and spaces. Please keep the format consistent with the original text.
    Preserve the original meaning and never alter technical terms or numerical data. 
    When encountering ambiguous content requiring author confirmation, directly implement the most reasonable revision.
    """
    try:
        st.subheader("æ¶¦è‰²ç»“æœ")
        content = ""  # å­˜å‚¨æ¶¦è‰²åçš„å†…å®¹
        reasoning_content = ""  # å­˜å‚¨æ¨ç†è¿‡ç¨‹å†…å®¹

        # è·å–é€‰æ‹©çš„æ¨¡å‹
        model = st.session_state.get("selected_model", "deepseek-chat")
            
        # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥æ˜¾ç¤ºæ¶¦è‰²ç»“æœ
        with st.container(height=300):
            reason_placeholder = st.empty()  # åˆ›å»ºæ¨ç†å†…å®¹çš„å ä½ç¬¦
            message_placeholder = st.empty()  # åˆ›å»ºæ¶¦è‰²ç»“æœçš„å ä½ç¬¦
            
            # è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹APIè¿›è¡Œæ¶¦è‰²
            for chunk in st.session_state.Client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"{prompt}\n\næ–‡æ®µå†…å®¹ï¼š{text}"}
                    ],
                    temperature=1.0,
                    stream=True
            ):
                # å¤„ç†æ¯ä¸ªè¿”å›çš„æ–‡æœ¬å—
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if getattr(delta, 'reasoning_content', None):
                        reasoning_content += delta.reasoning_content
                        reason_placeholder.markdown(
                            f"<div style='background:#f0f0f0; border-radius:5px; padding:10px; margin-bottom:10px; font-size:14px;'>"
                            f"ğŸ¤” {reasoning_content}</div>",
                            unsafe_allow_html=True
                        )
                    if delta and delta.content is not None:
                        content += delta.content
                        message_placeholder.markdown(
                            f"<div style='font-size:16px; margin-top:10px;'>{content}</div>",
                            unsafe_allow_html=True
                        )

        return content
    except Exception as e:
        st.error(f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        return None


def split_tex_into_paragraphs(tex_content):
    """
    å°†TEXæ–‡ä»¶å†…å®¹åˆ†å‰²æˆæ®µè½
    
    å‚æ•°:
        tex_content (str): TEXæ–‡ä»¶å†…å®¹
    
    è¿”å›:
        list: æ®µè½åˆ—è¡¨
    """
    # ç§»é™¤å¸¸è§çš„å‘½ä»¤å’Œç¯å¢ƒå£°æ˜
    tex_content = re.sub(r'(?<!\\)%.*$', '', tex_content, flags=re.MULTILINE)
    tex_content = re.sub(r'\\documentclass.*?{.*?}', '', tex_content)
    tex_content = re.sub(r'\\usepackage(\[.*?\])?{.*?}', '', tex_content)
    tex_content = re.sub(r'\\begin{document}', '', tex_content)
    tex_content = re.sub(r'\\end{document}', '', tex_content)
    tex_content = re.sub(r'\\maketitle', '', tex_content)
    tex_content = re.sub(r'\\usetikzlibrary.*?$', '', tex_content, flags=re.MULTILINE)
    tex_content = re.sub(r'\\bibliographystyle\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\bibliography\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\tableofcontents', '', tex_content)
    tex_content = re.sub(r'\\listoffigures', '', tex_content)
    tex_content = re.sub(r'\\listoftables', '', tex_content)
    tex_content = re.sub(r'\\setcounter\{.*?\}\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\graphicspath\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\newcommand\{.*?\}\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\renewcommand\{.*?\}\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\label\{.*?\}', '', tex_content)

    # æŒ‰ç©ºè¡Œåˆ†å‰²æ®µè½
    paragraphs = [p.strip() for p in tex_content.split('\n\n') if p.strip()]

    # å¦‚æœæ®µè½æ•°é‡å¤ªå°‘ï¼Œå°è¯•æŒ‰æ¢è¡Œç¬¦åˆ†å‰²
    if len(paragraphs) < 3:
        paragraphs = [p.strip() for p in tex_content.split('\n') if p.strip()]

    # è¿‡æ»¤æ‰åªåŒ…å«å‘½ä»¤çš„æ®µè½ï¼ˆå¦‚åªæœ‰\section{}çš„æ®µè½ï¼‰
    filtered_paragraphs = []
    for p in paragraphs:
        # å¦‚æœæ®µè½åªåŒ…å«å•ä¸€çš„å‘½ä»¤ï¼ˆå¦‚\section{}ï¼‰ï¼Œæˆ–è€…æ˜¯ç©ºæ®µè½ï¼Œåˆ™è·³è¿‡
        if not p or re.match(r'^\s*\\(section|subsection|subsubsection|paragraph|title|author|date|label)\{.*?\}\s*$',
                             p):
            continue
        # å¦‚æœæ®µè½é•¿åº¦è¿‡çŸ­ä¸”ä¸åŒ…å«å®è´¨æ€§æ–‡æœ¬å†…å®¹ï¼Œåˆ™è·³è¿‡
        if len(p) < 10 and not re.search(r'[a-zA-Z\u4e00-\u9fa5]', p):
            continue
        filtered_paragraphs.append(p)

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ®µè½ï¼Œè¿”å›æ•´ä¸ªå†…å®¹ä½œä¸ºä¸€ä¸ªæ®µè½
    if not filtered_paragraphs:
        filtered_paragraphs = [tex_content]

    return filtered_paragraphs


def TEX_Polishing():
    """
    TEXæ–‡ä»¶æ¶¦è‰²åŠŸèƒ½
    æä¾›TEXæ–‡ä»¶çš„æ®µè½æ¶¦è‰²åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ®µè½é€‰æ‹©ã€æ¶¦è‰²å’Œåº”ç”¨
    """
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([1, 1])
    # --- å·¦æ ï¼šå±•ç¤ºæ®µè½åˆ—è¡¨ ---
    with col1:
        st.session_state.TEX_content = st.session_state.uploaded_file.getvalue().decode('utf-8') if st.session_state.TEX_content is None else st.session_state.TEX_content
        st.session_state.tex_paragraphs = split_tex_into_paragraphs(st.session_state.TEX_content)
        st.subheader("TEX æ–‡ä»¶å†…å®¹ï¼ˆåŸå§‹æ®µè½ï¼‰")

        # åˆ›å»ºæ®µè½æ˜¾ç¤ºå®¹å™¨
        with st.container(height=800, border=False):
            # å¦‚æœå½“å‰æ­£åœ¨æ¶¦è‰²æŸä¸ªæ®µè½ï¼Œåªæ˜¾ç¤ºè¯¥æ®µè½
            if st.session_state.current_polishing_paragraph_index is not None and not st.session_state.show_all_paragraphs:
                i = st.session_state.current_polishing_paragraph_index
                paragraph = st.session_state.tex_paragraphs[i]
                with st.container(border=True, height=600):
                    st.markdown(f"**æ®µè½ {i + 1}**")
                    if st.button("â†©ï¸ è¿”å›æ‰€æœ‰æ®µè½", key="back_to_all_paragraphs"):
                        st.session_state.show_all_paragraphs = True
                        st.rerun()
                    # æ®µè½ç¼–è¾‘åŒºåŸŸ
                    modified_paragraph = st.text_area("æ®µè½è¯¦ç»†å†…å®¹", value=paragraph, height=500, key=f"Paragraph_details_{i}", disabled=False)
                    st.session_state.paragraph_to_polish = modified_paragraph
                    st.session_state.tex_paragraphs[i] = modified_paragraph
                    st.session_state.TEX_content = st.session_state.TEX_content.replace(paragraph, modified_paragraph, 1)
            else:
                # æ˜¾ç¤ºæ‰€æœ‰æ®µè½
                for i, paragraph in enumerate(st.session_state.tex_paragraphs):
                    with st.container(border=True, height=300):
                        st.markdown(f"**æ®µè½ {i + 1}**")
                        # æ®µè½ç¼–è¾‘åŒºåŸŸ
                        modified_paragraph = st.text_area("æ®µè½å†…å®¹", value=paragraph, height=250, key=f"paragraph_{i}", disabled=False)
                        st.session_state.tex_paragraphs[i] = modified_paragraph
                        st.session_state.TEX_content = st.session_state.TEX_content.replace(paragraph, modified_paragraph, 1)
                        # ç‚¹å‡»æ¶¦è‰²åï¼Œé‡ç½®çŠ¶æ€
                        if st.button(f"æ¶¦è‰²è¯¥æ®µè½", key=f"polish_btn_{i}"):
                            st.session_state.current_polishing_paragraph_index = i
                            st.session_state.paragraph_to_polish = modified_paragraph
                            st.session_state.show_all_paragraphs = False
                            st.rerun()

        # ä¸‹è½½æŒ‰é’®
        st.sidebar.download_button(
            label="ä¸‹è½½ TEX æ–‡ä»¶",
            data=st.session_state.TEX_content,
            file_name=f"{os.path.splitext(st.session_state.uploaded_file.name)[0]}_processed.tex",
            mime="text/plain",
            key="download_tex_button"
        )

        # æ’¤é”€æ“ä½œæŒ‰é’®
        if st.session_state.tex_history:
            if st.sidebar.button(f"â†©ï¸ æ’¤é”€ä¸Šæ¬¡è¦†ç›– ({len(st.session_state.tex_history)}æ­¥å¯æ’¤é”€)",
                                 key="undo_overwrite_button"):
                st.session_state.TEX_content = st.session_state.tex_history.pop()
                st.success("å·²æ’¤é”€ä¸Šæ¬¡è¦†ç›–æ“ä½œï¼")
                st.session_state.paragraph_to_polish = ""
                st.session_state.polished_paragraph = None
                st.session_state.tex_paragraphs = split_tex_into_paragraphs(st.session_state.TEX_content)
                st.rerun()
        else:
            st.sidebar.button("â†©ï¸ æ’¤é”€ä¸Šæ¬¡è¦†ç›–", key="undo_overwrite_button_disabled", disabled=True)

    # --- å³æ ï¼šæ¶¦è‰²äº¤äº’ ---
    with col2:
        if st.session_state.current_polishing_paragraph_index is not None and st.session_state.paragraph_to_polish:
            st.subheader("æ®µè½æ¶¦è‰²")

            # æ¶¦è‰²æç¤ºè¯ç¼–è¾‘åŒºåŸŸ
            st.session_state.polishing_prompt = st.text_area(
                "æ¶¦è‰²è¦æ±‚ (Prompt):",
                value=st.session_state.polishing_prompt,
                height=100,
                key="prompt_input"
            )

            # å¼€å§‹æ¶¦è‰²æŒ‰é’®
            if st.button("å¼€å§‹æ¶¦è‰²", key="start_polish_button"):
                st.session_state.polished_paragraph = None
                with st.spinner("æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œæ¶¦è‰²..."):
                    st.session_state.polished_paragraph = polish_text_with_llm(
                        st.session_state.paragraph_to_polish,
                        st.session_state.polishing_prompt
                    )

            if st.session_state.polished_paragraph is not None:
                polish_col1, polish_col2 = st.columns(2)
                with polish_col1:
                    # åº”ç”¨æ¶¦è‰²ç»“æœæŒ‰é’®
                    if st.button("âœ… åº”ç”¨æ¶¦è‰²ç»“æœ", key="apply_polish_button"):
                        # ä¿å­˜å½“å‰å†…å®¹åˆ°å†å²è®°å½•
                        st.session_state.tex_history.append(st.session_state.TEX_content)

                        # è·å–åŸå§‹æ®µè½
                        original_paragraph = st.session_state.tex_paragraphs[
                            st.session_state.current_polishing_paragraph_index]

                        try:
                            # æ›¿æ¢æ®µè½å†…å®¹
                            new_content = st.session_state.TEX_content.replace(
                                original_paragraph,
                                st.session_state.polished_paragraph,
                                1
                            )

                            # æ£€æŸ¥æ›¿æ¢æ˜¯å¦æˆåŠŸ
                            if new_content == st.session_state.TEX_content:
                                st.error("æ›¿æ¢å¤±è´¥ï¼šè¯·å°è¯•æ‰‹åŠ¨æ›´æ–°")
                            else:
                                st.session_state.TEX_content = new_content
                                st.session_state.tex_paragraphs[
                                    st.session_state.current_polishing_paragraph_index] = st.session_state.polished_paragraph
                                st.success("æ®µè½å·²æ›´æ–°ï¼")
                                # é‡ç½®çŠ¶æ€
                                st.session_state.paragraph_to_polish = ""
                                st.session_state.polished_paragraph = None
                                st.session_state.current_polishing_paragraph_index = None
                                st.session_state.show_all_paragraphs = True
                                st.rerun()
                        except Exception as e:
                            st.error(f"åº”ç”¨ä¿®æ”¹æ—¶å‡ºé”™: {str(e)}")

                with polish_col2:
                    # å–æ¶ˆæŒ‰é’®
                    if st.button("âŒ å–æ¶ˆ", key="cancel_polish_button"):
                        # é‡ç½®çŠ¶æ€
                        st.session_state.polished_paragraph = None
                        st.session_state.paragraph_to_polish = ""
                        st.session_state.current_polishing_paragraph_index = None
                        st.session_state.show_all_paragraphs = True
                        st.rerun()

        elif st.session_state.TEX_content is not None:
            st.info("è¯·ä»å·¦ä¾§é€‰æ‹©ä¸€ä¸ªæ®µè½è¿›è¡Œæ¶¦è‰²")


def Textual_polishing():
    """
    æ–‡æœ¬æ‹¼å†™æ£€æŸ¥åŠŸèƒ½
    æä¾›æ™®é€šæ–‡æœ¬çš„è¯­æ³•å’Œæ‹¼å†™æ£€æŸ¥åŠŸèƒ½
    """
    st.subheader("æ–‡æœ¬æ‹¼å†™æ£€æŸ¥")
    # æ–‡æœ¬è¾“å…¥åŒºåŸŸ
    input_text = st.text_area(
        "è¯·è¾“å…¥éœ€è¦æ£€æŸ¥çš„æ–‡æœ¬ï¼š",
        height=200,
        key="text_input"
    )
    if st.button("å¼€å§‹æ£€æŸ¥", key="check_button"):
        col1, col2 = st.columns([1, 1])
        try:
            tool = language_tool_python.LanguageTool('en-US')
            # æ£€æŸ¥æ–‡æœ¬
            matches = tool.check(input_text)
            tool.close()

            # è¿‡æ»¤æ‰æ‰€æœ‰Possible spelling mistake foundç±»å‹çš„é”™è¯¯
            filtered_matches = [match for match in matches if match.message != 'Possible spelling mistake found.']
            
            if not filtered_matches:
                st.success("æœªå‘ç°è¯­æ³•æˆ–æ‹¼å†™é”™è¯¯ï¼")
            else:
                with col1:
                    # å±•ç¤ºé”™è¯¯è¯¦æƒ…
                    st.markdown("### é”™è¯¯è¯¦æƒ…")
                    for i, match in enumerate(filtered_matches):
                        st.markdown(f"""
                        <div style="font-size: 14px; padding: 10px; margin: 5px 0; background-color: #f5f5f5; border-radius: 4px;">
                            <div><span style="font-weight: bold;">é”™è¯¯ç±»å‹</span>: {match.ruleId}</div>
                            <div><span style="font-weight: bold;">é”™è¯¯ä½ç½®</span>: {match.offset}-{match.offset + match.errorLength}</div>
                            <div><span style="font-weight: bold;">é”™è¯¯å†…å®¹</span>: <span style="color: #ff4b4b;">{input_text[match.offset:match.offset + match.errorLength]}</span></div>
                            <div><span style="font-weight: bold;">å»ºè®®ä¿®æ”¹</span>: {match.replacements[0] if match.replacements else 'æ— å»ºè®®'}</div>
                            <div><span style="font-weight: bold;">é”™è¯¯è¯´æ˜</span>: {match.message}</div>
                        </div>
                        """, unsafe_allow_html=True)
                with col2:
                    # ä¿®æ”¹é¢„è§ˆ
                    st.markdown("### é€æ¡ä¿®æ”¹é¢„è§ˆ")
                    for i, match in enumerate(filtered_matches):
                        if match.replacements:
                            modified_segment = (
                                    input_text[:match.offset] +
                                    f"**{match.replacements[0]}**" +
                                    input_text[match.offset + match.errorLength:]
                            )
                            st.markdown(modified_segment)
                            st.markdown('--------------------')

                st.markdown("### æœ€ç»ˆä¿®æ”¹ç»“æœ")
                corrected_text = input_text
                for match in sorted(filtered_matches, key=lambda x: -x.offset):
                    if match.replacements:
                        corrected_text = (
                                corrected_text[:match.offset] +
                                f"**{match.replacements[0]}**" +
                                corrected_text[match.offset + match.errorLength:]
                        )
                st.markdown(corrected_text)

        except Exception as e:
            st.error(f"æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")


def Political_censorship():
    """
    æ”¿æ²»å®¡æŸ¥åŠŸèƒ½
    æä¾›TEXæ–‡ä»¶çš„æ”¿æ²»å®¡æŸ¥åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ®µè½é€‰æ‹©ã€å®¡æŸ¥å’Œç»“æœå±•ç¤º
    """
    # è·å–TEXæ–‡ä»¶å†…å®¹
    st.session_state.TEX_content = st.session_state.uploaded_file.getvalue().decode(
        'utf-8') if st.session_state.TEX_content is None else st.session_state.TEX_content
    st.session_state.tex_paragraphs = split_tex_into_paragraphs(st.session_state.TEX_content)

    col1, col2 = st.columns([1, 1])

    # å·¦æ ï¼šæ˜¾ç¤ºæ®µè½åˆ—è¡¨
    with col1:
        st.subheader("TEX æ–‡ä»¶å†…å®¹ï¼ˆåŸå§‹æ®µè½ï¼‰")
        with st.container(height=800, border=False):
            if st.session_state.current_censorship_paragraph_index is not None and not st.session_state.show_all_censorship_paragraphs:
                i = st.session_state.current_censorship_paragraph_index
                paragraph = st.session_state.tex_paragraphs[i]
                with st.container(border=True, height=600):
                    st.markdown(f"**æ®µè½ {i + 1}**")
                    if st.button("â†©ï¸ è¿”å›æ‰€æœ‰æ®µè½", key="back_to_all_censorship_paragraphs"):
                        st.session_state.show_all_censorship_paragraphs = True
                        st.rerun()
                    st.markdown(paragraph)
                    st.session_state.paragraph_to_censor = paragraph
            else:
                for i, paragraph in enumerate(st.session_state.tex_paragraphs):
                    with st.container(border=True, height=300):
                        st.markdown(f"**æ®µè½ {i + 1}**")
                        st.markdown(paragraph)
                        if st.button(f"å®¡æŸ¥è¯¥æ®µè½", key=f"censor_btn_{i}"):
                            st.session_state.current_censorship_paragraph_index = i
                            st.session_state.show_all_censorship_paragraphs = False
                            st.rerun()

    # å³æ ï¼šå®¡æŸ¥äº¤äº’
    with col2:
        if st.session_state.current_censorship_paragraph_index is not None and st.session_state.paragraph_to_censor:
            st.subheader("æ®µè½æ”¿æ²»å®¡æŸ¥")
            st.markdown(f"**å½“å‰å®¡æŸ¥æ®µè½ {st.session_state.current_censorship_paragraph_index + 1}**")
            st.markdown(st.session_state.paragraph_to_censor)

            st.session_state.censorship_prompt = st.text_area(
                "å®¡æŸ¥è¦æ±‚ (Prompt):",
                value=st.session_state.censorship_prompt,
                height=100,
                key="censorship_prompt_input"
            )

            if st.button("å¼€å§‹æ”¿æ²»å®¡æŸ¥", key="start_censorship_button"):
                with st.spinner("æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ”¿æ²»å®¡æŸ¥..."):
                    system_prompt = """
                    ä½ æ˜¯ä¸€ä½æ”¿æ²»å®¡æŸ¥ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯å¯¹ä¸‹è¿°æ–‡ç« æ®µè½è¿›è¡Œæ”¿æ²»å®¡æŸ¥ï¼Œå¹¶ï¼š
                    1. è¯†åˆ«å¯èƒ½å­˜åœ¨çš„æ”¿æ²»æ•æ„Ÿå†…å®¹ï¼›
                    2. è¯„ä¼°å†…å®¹çš„æ”¿æ²»å€¾å‘æ€§ï¼›
                    3. æŒ‡å‡ºå¯èƒ½è¿åå›½å®¶æ³•å¾‹æ³•è§„çš„å†…å®¹ï¼›
                    4. æä¾›è¯¦ç»†çš„å®¡æŸ¥æ„è§ã€‚
                    è¯·æä¾›å…¨é¢çš„å®¡æŸ¥æŠ¥å‘Šï¼ŒåŒ…æ‹¬å‘ç°çš„é—®é¢˜å’Œå»ºè®®ã€‚
                    """
                    
                    try:
                        model = st.session_state.get("selected_model", "deepseek-chat")
                        content = ""
                        # åˆ›å»ºå®¹å™¨æ˜¾ç¤ºå®¡æŸ¥ç»“æœ
                        with st.container(height=300):
                            message_placeholder = st.empty()
                            # è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹APIè¿›è¡Œå®¡æŸ¥
                            for chunk in st.session_state.Client.chat.completions.create(
                                    model=model,
                                    messages=[
                                        {"role": "system", "content": system_prompt},
                                        {"role": "user", "content": f"{st.session_state.censorship_prompt}\n\næ®µè½å†…å®¹ï¼š{st.session_state.paragraph_to_censor}"}
                                    ],
                                    temperature=0.7,
                                    stream=True
                            ):
                                # å¤„ç†æ¯ä¸ªè¿”å›çš„æ–‡æœ¬å—
                                if chunk.choices and len(chunk.choices) > 0:
                                    delta = chunk.choices[0].delta
                                    if delta and delta.content is not None:
                                        content += delta.content
                                        message_placeholder.markdown(
                                            f"<div style='font-size:16px; margin-top:10px;'>{content}</div>",
                                            unsafe_allow_html=True
                                        )

                        # ä¿å­˜å®¡æŸ¥ç»“æœ
                        st.session_state.censorship_results[st.session_state.current_censorship_paragraph_index] = content
                        st.session_state.censorship_result = content
                        st.rerun()
                    except Exception as e:
                        st.error(f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")

            if st.session_state.current_censorship_paragraph_index in st.session_state.censorship_results:
                st.markdown("### å®¡æŸ¥ç»“æœ")
                st.markdown(st.session_state.censorship_results[st.session_state.current_censorship_paragraph_index])

                if st.button("è¿”å›æ‰€æœ‰æ®µè½", key="return_to_all_paragraphs_censorship"):
                    st.session_state.show_all_censorship_paragraphs = True
                    st.rerun()

        elif st.session_state.censorship_results:
            st.subheader("æ‰€æœ‰æ®µè½å®¡æŸ¥ç»“æœæ‘˜è¦")
            
            for i, paragraph in enumerate(st.session_state.tex_paragraphs):
                with st.expander(f"æ®µè½ {i + 1} å®¡æŸ¥ç»“æœ", expanded=False):
                    if i in st.session_state.censorship_results:
                        st.markdown(st.session_state.censorship_results[i])
                    else:
                        st.info("è¯¥æ®µè½å°šæœªå®¡æŸ¥")
        
        else:
            st.info("è¯·ä»å·¦ä¾§é€‰æ‹©ä¸€ä¸ªæ®µè½è¿›è¡Œæ”¿æ²»å®¡æŸ¥")


def main():
    """
    ä¸»å‡½æ•°ï¼šåº”ç”¨ç¨‹åºçš„å…¥å£ç‚¹
    åˆå§‹åŒ–åº”ç”¨ç¨‹åºå¹¶è®¾ç½®ç•Œé¢
    """
    # åˆå§‹åŒ–åº”ç”¨ç¨‹åº
    initialization()
    st.title("å­¦æœ¯ç‚¼é‡‘æœ¯")

    # æ·»åŠ ä½¿ç”¨è¯´æ˜
    with st.expander("ä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ğŸŒŸ **è®ºæ–‡æ¶¦è‰²ä¸å¤„ç†å·¥å…·ä½¿ç”¨æŒ‡å—** ğŸŒŸ
        
        ğŸ§© **ç³»ç»Ÿäº®ç‚¹**ï¼š
        
        âœ… æ™ºèƒ½æ¶¦è‰²å­¦æœ¯è®ºæ–‡<br>
        âœ… è¯­æ³•ä¸æ‹¼å†™æ£€æŸ¥<br>
        âœ… æ”¿æ²»å†…å®¹å®¡æŸ¥<br>
        âœ… æ”¯æŒTEXæ ¼å¼æ–‡ä»¶å¤„ç†<br>

        ğŸ› ï¸ **åŠŸèƒ½æ¨¡å—**ï¼š
        
        1ï¸âƒ£ **æ–‡æ®µè¯­æ³•æ£€æŸ¥**ï¼š<br>
        - è¾“å…¥ä»»æ„æ–‡æœ¬è¿›è¡Œè¯­æ³•å’Œæ‹¼å†™æ£€æŸ¥<br>
        - æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯åŠä¿®æ”¹å»ºè®®<br>
        - æä¾›é€æ¡ä¿®æ”¹é¢„è§ˆå’Œæœ€ç»ˆä¿®æ”¹ç»“æœ<br>
        
        2ï¸âƒ£ **TEXæ–‡æ®µæ¶¦è‰²**ï¼š<br>
        - ä¸Šä¼ TEXæ ¼å¼è®ºæ–‡æ–‡ä»¶<br>
        - æ™ºèƒ½åˆ†æ®µå¤„ç†è®ºæ–‡å†…å®¹<br>
        - ä½¿ç”¨AIæ¨¡å‹è¿›è¡Œä¸“ä¸šæ¶¦è‰²<br>
        - æ”¯æŒé€æ®µæ¶¦è‰²å’Œæ•´ä½“åº”ç”¨<br>
        - æä¾›æ¶¦è‰²å†å²è®°å½•å’Œæ’¤é”€åŠŸèƒ½<br>
        
        3ï¸âƒ£ **æ”¿æ²»å®¡æŸ¥**ï¼š<br>
        - å¯¹è®ºæ–‡å†…å®¹è¿›è¡Œæ”¿æ²»æ•æ„Ÿæ€§å®¡æŸ¥<br>
        - è¯†åˆ«æ½œåœ¨çš„æ”¿æ²»æ•æ„Ÿå†…å®¹<br>
        - æä¾›è¯¦ç»†çš„å®¡æŸ¥æŠ¥å‘Š<br>

        ğŸ“ **æ“ä½œæµç¨‹**ï¼š
        1. åœ¨ä¾§è¾¹æ é€‰æ‹©æ¨¡å‹å’Œä¸Šä¼ TEXæ–‡ä»¶
        2. é€‰æ‹©éœ€è¦ä½¿ç”¨çš„åŠŸèƒ½æ¨¡å—
        3. æŒ‰ç…§ç•Œé¢æç¤ºè¿›è¡Œæ“ä½œ
        4. ä¸‹è½½å¤„ç†åçš„æ–‡ä»¶

        ğŸ’¡ **ä½¿ç”¨æŠ€å·§**ï¼š
        - æ¶¦è‰²å‰å¯è‡ªå®šä¹‰æ¶¦è‰²æç¤ºè¯<br>
        - ä½¿ç”¨æ’¤é”€åŠŸèƒ½å¯æ¢å¤ä¹‹å‰çš„ä¿®æ”¹<br>
        - å¯éšæ—¶ä¸‹è½½å¤„ç†åçš„æ–‡ä»¶ä¿å­˜ç»“æœ
        """, unsafe_allow_html=True)

    # æ¸…é™¤æ‰€æœ‰è®°å½•æŒ‰é’®
    if st.sidebar.button("æ¸…é™¤æ‰€æœ‰è®°å½•"):
        keys_to_keep = ['previous_page']
        for key in list(st.session_state.keys()):
            if key not in keys_to_keep:
                del st.session_state[key]
        initialization()
        st.rerun()

    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        # æ–‡ä»¶ä¸Šä¼ å›è°ƒå‡½æ•°
        def on_file_change():
            # é‡ç½®çŠ¶æ€
            st.session_state.TEX_content = None
            st.session_state.paragraph_to_polish = ""
            st.session_state.polished_paragraph = None
            st.session_state.tex_history = []
            st.session_state.tex_paragraphs = []
            st.session_state.current_polishing_paragraph_index = None
            st.session_state.current_censorship_paragraph_index = None
            st.session_state.show_all_censorship_paragraphs = True
            st.session_state.paragraph_to_censor = ""
            st.session_state.censorship_results = {}
            st.session_state.censorship_result = None
            if 'previous_TEX_content' in st.session_state:
                del st.session_state['previous_TEX_content']

        # æ–‡ä»¶ä¸Šä¼ å™¨
        st.session_state.uploaded_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=['tex'],
            key="file_uploader",
            on_change=on_file_change
        )

        # æ¨¡å‹é€‰æ‹©
        st.sidebar.markdown("### æ¨¡å‹é€‰æ‹©")

        model_names = list(HIGHSPEED_MODEL_MAPPING.keys())
        selected_model_name = st.sidebar.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=model_names,
            index=0
        )
        st.session_state.selected_model = HIGHSPEED_MODEL_MAPPING[selected_model_name]

    # åˆ›å»ºé€‰é¡¹å¡
    tab1, tab2, tab3 = st.tabs(['æ–‡æ®µè¯­æ³•æ£€æŸ¥', 'texæ–‡æ®µæ¶¦è‰²', 'æ”¿æ²»å®¡æŸ¥'])
    with tab1:
        Textual_polishing()

    with tab2:
        if st.session_state.uploaded_file is not None:
            TEX_Polishing()
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")

    with tab3:
        if st.session_state.uploaded_file is not None:
            Political_censorship()
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")


if 'previous_page' not in st.session_state:
    st.session_state.previous_page = 'PaperPolishing'
current_page = 'PaperPolishing'
if current_page != st.session_state.previous_page:
    st.session_state.clear()
    st.session_state.previous_page = current_page

main()
