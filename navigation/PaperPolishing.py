import streamlit as st
import os
import re
from openai import OpenAI
import language_tool_python
from pages.Functions.Constants import HIGHSPEED_MODEL_MAPPING

st.set_page_config(
    page_title="è®ºæ–‡æ¶¦è‰²ä¸å¤„ç†å·¥å…·",
    layout="wide",
    initial_sidebar_state="expanded"
)


def initialization():
    if "Client" not in st.session_state:
        st.session_state.Client = OpenAI(api_key=os.environ.get('ZhiZz_API_KEY'), base_url=os.environ.get('ZhiZz_URL'))
    if "uploaded_file" not in st.session_state:
        st.session_state.uploaded_file = None
    if "TEX_content" not in st.session_state:
        st.session_state.TEX_content = None
    if "tex_history" not in st.session_state:
        st.session_state.tex_history = []
    if "tex_paragraphs" not in st.session_state:
        st.session_state.tex_paragraphs = []
    if "current_polishing_paragraph_index" not in st.session_state:
        st.session_state.current_polishing_paragraph_index = None
    if "show_all_paragraphs" not in st.session_state:
        st.session_state.show_all_paragraphs = True

    if "paragraph_to_polish" not in st.session_state:
        st.session_state.paragraph_to_polish = ""
    if "polishing_prompt" not in st.session_state:
        st.session_state.polishing_prompt = ("ä½ æ˜¯ä¸€ä½å­¦æœ¯è®ºæ–‡è¯„å®¡ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡è¯„å®¡ä¸‹è¿°æ–‡ç« æ®µè½ï¼Œå¹¶ï¼š"
                                             "1. ä¿®æ­£è¯­æ³•é”™è¯¯å’Œæ‹¼å†™é”™è¯¯ï¼› "
                                             "2. ä¼˜åŒ–å¥å¼ç»“æ„æå‡æµç•…æ€§ï¼› "
                                             "3. ç¡®ä¿ä¸“ä¸šæœ¯è¯­å‡†ç¡®ï¼› "
                                             "4. ç»´æŒå­¦æœ¯å†™ä½œè§„èŒƒã€‚è¯·ä¸¥æ ¼ç¡®ä¿è¾“å‡ºä»…åŒ…å«æ¶¦è‰²åçš„æ–‡æ®µï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€è¯´æ˜ã€æ³¨é‡Šç­‰å†…å®¹;"
                                             "5. ä¸è¦ä¿®æ”¹ä»»ä½•å¼•ç”¨ã€æ®µè½æ ‡è®°å†…å®¹ï¼Œå¦‚\\citeã€\\sectionã€‚"
                                             "6. ä¸è¦ä¿®æ”¹æ ¼å¼å†…å®¹ï¼Œå¦‚æ¢è¡Œã€ç¼©è¿›ã€ç©ºæ ¼ã€‚æ ¼å¼è¯·ä¸åŸæ–‡ä¿æŒä¸€è‡´"
                                             "ä¿®æ”¹è¿‡ç¨‹éœ€ä¿æŒåŸæ–‡æ ¸å¿ƒå«ä¹‰ä¸å˜ï¼Œä¸å¾—æ›´æ”¹ä¸“ä¸šæœ¯è¯­å’Œæ•°æ®ä¿¡æ¯ã€‚")
    if "polished_paragraph" not in st.session_state:
        st.session_state.polished_paragraph = None
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = "deepseek-chat"
    if "censorship_prompt" not in st.session_state:
        st.session_state.censorship_prompt = ("ä½ æ˜¯ä¸€ä½æ”¿æ²»å®¡æŸ¥ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯å¯¹ä¸‹è¿°æ–‡ç« è¿›è¡Œæ”¿æ²»å®¡æŸ¥ï¼Œå¹¶ï¼š"
                                             "1. è¯†åˆ«å¯èƒ½å­˜åœ¨çš„æ”¿æ²»æ•æ„Ÿå†…å®¹ï¼›"
                                             "2. è¯„ä¼°å†…å®¹çš„æ”¿æ²»å€¾å‘æ€§ï¼›"
                                             "3. æŒ‡å‡ºå¯èƒ½è¿åå›½å®¶æ³•å¾‹æ³•è§„çš„å†…å®¹ï¼›"
                                             "4. æä¾›è¯¦ç»†çš„å®¡æŸ¥æ„è§ã€‚")
    if "censorship_result" not in st.session_state:
        st.session_state.censorship_result = None
    if "current_censorship_paragraph_index" not in st.session_state:
        st.session_state.current_censorship_paragraph_index = None
    if "show_all_censorship_paragraphs" not in st.session_state:
        st.session_state.show_all_censorship_paragraphs = True
    if "paragraph_to_censor" not in st.session_state:
        st.session_state.paragraph_to_censor = ""
    if "censorship_results" not in st.session_state:
        st.session_state.censorship_results = {}


def polish_text_with_llm(text, prompt):
    system_prompt = """
    You are a professional academic writing optimization assistant specializing in refining and proofreading academic document excerpts. 
    Your core tasks are: 
    1. Correct grammatical errors and spelling mistakes 
    2. Optimize sentence structures for improved fluency 
    3. Ensure accurate usage of technical terminology 
    4. Maintain academic writing standards. Strictly provide ONLY the polished text without any explanations, notes, or additional comments. 
    5. Do not modify any citation or paragraph mark content, such as \\cite, \\section.
    6. Do not modify the formatting, such as line breaks, indents, and spaces. Please keep the format consistent with the original text.
    Preserve the original meaning and never alter technical terms or numerical data. 
    When encountering ambiguous content requiring author confirmation, directly implement the most reasonable revision.
    """
    try:
        st.subheader("æ¶¦è‰²ç»“æœ")
        content = ""
        reasoning_content = ""

        model = st.session_state.get("selected_model", "deepseek-chat")
            
        with st.container(height=300):
            reason_placeholder = st.empty()
            message_placeholder = st.empty()
            for chunk in st.session_state.Client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"{prompt}\n\næ–‡æ®µå†…å®¹ï¼š{text}"}
                    ],
                    temperature=1.0,
                    stream=True
            ):
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if getattr(delta, 'reasoning_content', None):
                        reasoning_content += delta.reasoning_content
                        reason_placeholder.markdown(
                            f"<div style='background:#f0f0f0; border-radius:5px; padding:10px; margin-bottom:10px; font-size:14px;'>"
                            f"ğŸ¤” {reasoning_content}</div>",
                            unsafe_allow_html=True
                        )
                    if delta and delta.content is not None:
                        content += delta.content
                        message_placeholder.markdown(
                            f"<div style='font-size:16px; margin-top:10px;'>{content}</div>",
                            unsafe_allow_html=True
                        )

        return content
    except Exception as e:
        st.error(f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        return None


def split_tex_into_paragraphs(tex_content):
    # ç§»é™¤å¸¸è§çš„å‘½ä»¤å’Œç¯å¢ƒå£°æ˜
    tex_content = re.sub(r'(?<!\\)%.*$', '', tex_content, flags=re.MULTILINE)
    tex_content = re.sub(r'\\documentclass.*?{.*?}', '', tex_content)
    tex_content = re.sub(r'\\usepackage(\[.*?\])?{.*?}', '', tex_content)
    tex_content = re.sub(r'\\begin{document}', '', tex_content)
    tex_content = re.sub(r'\\end{document}', '', tex_content)
    tex_content = re.sub(r'\\maketitle', '', tex_content)
    tex_content = re.sub(r'\\usetikzlibrary.*?$', '', tex_content, flags=re.MULTILINE)
    tex_content = re.sub(r'\\bibliographystyle\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\bibliography\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\tableofcontents', '', tex_content)
    tex_content = re.sub(r'\\listoffigures', '', tex_content)
    tex_content = re.sub(r'\\listoftables', '', tex_content)
    tex_content = re.sub(r'\\setcounter\{.*?\}\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\graphicspath\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\newcommand\{.*?\}\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\renewcommand\{.*?\}\{.*?\}', '', tex_content)
    tex_content = re.sub(r'\\label\{.*?\}', '', tex_content)

    paragraphs = [p.strip() for p in tex_content.split('\n\n') if p.strip()]

    if len(paragraphs) < 3:
        paragraphs = [p.strip() for p in tex_content.split('\n') if p.strip()]

    # è¿‡æ»¤æ‰åªåŒ…å«å‘½ä»¤çš„æ®µè½ï¼ˆå¦‚åªæœ‰\section{}çš„æ®µè½ï¼‰
    filtered_paragraphs = []
    for p in paragraphs:
        # å¦‚æœæ®µè½åªåŒ…å«å•ä¸€çš„å‘½ä»¤ï¼ˆå¦‚\section{}ï¼‰ï¼Œæˆ–è€…æ˜¯ç©ºæ®µè½ï¼Œåˆ™è·³è¿‡
        if not p or re.match(r'^\s*\\(section|subsection|subsubsection|paragraph|title|author|date|label)\{.*?\}\s*$',
                             p):
            continue
        # å¦‚æœæ®µè½é•¿åº¦è¿‡çŸ­ä¸”ä¸åŒ…å«å®è´¨æ€§æ–‡æœ¬å†…å®¹ï¼Œåˆ™è·³è¿‡
        if len(p) < 10 and not re.search(r'[a-zA-Z\u4e00-\u9fa5]', p):
            continue
        filtered_paragraphs.append(p)

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ®µè½ï¼Œè¿”å›æ•´ä¸ªå†…å®¹ä½œä¸ºä¸€ä¸ªæ®µè½
    if not filtered_paragraphs:
        filtered_paragraphs = [tex_content]

    return filtered_paragraphs


def TEX_Polishing():
    col1, col2 = st.columns([1, 1])
    # --- å·¦æ ï¼šå±•ç¤ºæ®µè½åˆ—è¡¨ ---
    with col1:
        st.session_state.TEX_content = st.session_state.uploaded_file.getvalue().decode('utf-8') if st.session_state.TEX_content is None else st.session_state.TEX_content
        st.session_state.tex_paragraphs = split_tex_into_paragraphs(st.session_state.TEX_content)
        st.subheader("TEX æ–‡ä»¶å†…å®¹ï¼ˆåŸå§‹æ®µè½ï¼‰")

        with st.container(height=800, border=False):
            # å¦‚æœå½“å‰æ­£åœ¨æ¶¦è‰²æŸä¸ªæ®µè½ï¼Œåªæ˜¾ç¤ºè¯¥æ®µè½
            if st.session_state.current_polishing_paragraph_index is not None and not st.session_state.show_all_paragraphs:
                i = st.session_state.current_polishing_paragraph_index
                paragraph = st.session_state.tex_paragraphs[i]
                with st.container(border=True, height=600):
                    st.markdown(f"**æ®µè½ {i + 1}**")
                    if st.button("â†©ï¸ è¿”å›æ‰€æœ‰æ®µè½", key="back_to_all_paragraphs"):
                        st.session_state.show_all_paragraphs = True
                        st.rerun()
                    modified_paragraph = st.text_area("æ®µè½è¯¦ç»†å†…å®¹", value=paragraph, height=500, key=f"Paragraph_details_{i}", disabled=False)
                    st.session_state.paragraph_to_polish = modified_paragraph
                    st.session_state.tex_paragraphs[i] = modified_paragraph
                    st.session_state.TEX_content = st.session_state.TEX_content.replace(paragraph, modified_paragraph, 1)
            else:
                for i, paragraph in enumerate(st.session_state.tex_paragraphs):
                    with st.container(border=True, height=300):
                        st.markdown(f"**æ®µè½ {i + 1}**")
                        modified_paragraph = st.text_area("æ®µè½å†…å®¹", value=paragraph, height=250, key=f"paragraph_{i}", disabled=False)
                        st.session_state.tex_paragraphs[i] = modified_paragraph
                        st.session_state.TEX_content = st.session_state.TEX_content.replace(paragraph, modified_paragraph, 1)
                        if st.button(f"æ¶¦è‰²è¯¥æ®µè½", key=f"polish_btn_{i}"):
                            st.session_state.current_polishing_paragraph_index = i
                            st.session_state.paragraph_to_polish = modified_paragraph
                            st.session_state.show_all_paragraphs = False
                            st.rerun()

        st.sidebar.download_button(
            label="ä¸‹è½½ TEX æ–‡ä»¶",
            data=st.session_state.TEX_content,
            file_name=f"{os.path.splitext(st.session_state.uploaded_file.name)[0]}_processed.tex",
            mime="text/plain",
            key="download_tex_button"
        )

        if st.session_state.tex_history:
            if st.sidebar.button(f"â†©ï¸ æ’¤é”€ä¸Šæ¬¡è¦†ç›– ({len(st.session_state.tex_history)}æ­¥å¯æ’¤é”€)",
                                 key="undo_overwrite_button"):
                st.session_state.TEX_content = st.session_state.tex_history.pop()
                st.success("å·²æ’¤é”€ä¸Šæ¬¡è¦†ç›–æ“ä½œï¼")
                st.session_state.paragraph_to_polish = ""
                st.session_state.polished_paragraph = None
                st.session_state.tex_paragraphs = split_tex_into_paragraphs(st.session_state.TEX_content)
                st.rerun()
        else:
            st.sidebar.button("â†©ï¸ æ’¤é”€ä¸Šæ¬¡è¦†ç›–", key="undo_overwrite_button_disabled", disabled=True)

    # --- å³æ ï¼šæ¶¦è‰²äº¤äº’ ---
    with col2:
        if st.session_state.current_polishing_paragraph_index is not None and st.session_state.paragraph_to_polish:
            st.subheader("æ®µè½æ¶¦è‰²")

            st.session_state.polishing_prompt = st.text_area(
                "æ¶¦è‰²è¦æ±‚ (Prompt):",
                value=st.session_state.polishing_prompt,
                height=100,
                key="prompt_input"
            )

            if st.button("å¼€å§‹æ¶¦è‰²", key="start_polish_button"):
                st.session_state.polished_paragraph = None
                with st.spinner("æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œæ¶¦è‰²..."):
                    st.session_state.polished_paragraph = polish_text_with_llm(
                        st.session_state.paragraph_to_polish,
                        st.session_state.polishing_prompt
                    )

            if st.session_state.polished_paragraph is not None:
                polish_col1, polish_col2 = st.columns(2)
                with polish_col1:
                    if st.button("âœ… åº”ç”¨æ¶¦è‰²ç»“æœ", key="apply_polish_button"):
                        st.session_state.tex_history.append(st.session_state.TEX_content)

                        original_paragraph = st.session_state.tex_paragraphs[
                            st.session_state.current_polishing_paragraph_index]

                        try:
                            new_content = st.session_state.TEX_content.replace(
                                original_paragraph,
                                st.session_state.polished_paragraph,
                                1
                            )

                            if new_content == st.session_state.TEX_content:
                                st.error("æ›¿æ¢å¤±è´¥ï¼šè¯·å°è¯•æ‰‹åŠ¨æ›´æ–°")
                            else:
                                st.session_state.TEX_content = new_content
                                st.session_state.tex_paragraphs[
                                    st.session_state.current_polishing_paragraph_index] = st.session_state.polished_paragraph
                                st.success("æ®µè½å·²æ›´æ–°ï¼")
                                st.session_state.paragraph_to_polish = ""
                                st.session_state.polished_paragraph = None
                                st.session_state.current_polishing_paragraph_index = None
                                st.session_state.show_all_paragraphs = True
                                st.rerun()
                        except Exception as e:
                            st.error(f"åº”ç”¨ä¿®æ”¹æ—¶å‡ºé”™: {str(e)}")

                with polish_col2:
                    if st.button("âŒ å–æ¶ˆ", key="cancel_polish_button"):
                        st.session_state.polished_paragraph = None
                        st.session_state.paragraph_to_polish = ""
                        st.session_state.current_polishing_paragraph_index = None
                        st.session_state.show_all_paragraphs = True
                        st.rerun()

        elif st.session_state.TEX_content is not None:
            st.info("è¯·ä»å·¦ä¾§é€‰æ‹©ä¸€ä¸ªæ®µè½è¿›è¡Œæ¶¦è‰²")


def Textual_polishing():
    st.subheader("æ–‡æœ¬æ‹¼å†™æ£€æŸ¥")
    input_text = st.text_area(
        "è¯·è¾“å…¥éœ€è¦æ£€æŸ¥çš„æ–‡æœ¬ï¼š",
        height=200,
        key="text_input"
    )
    if st.button("å¼€å§‹æ£€æŸ¥", key="check_button"):
        col1, col2 = st.columns([1, 1])
        try:
            tool = language_tool_python.LanguageTool('en-US')
            matches = tool.check(input_text)
            tool.close()

            # è¿‡æ»¤æ‰æ‰€æœ‰Possible spelling mistake foundç±»å‹çš„é”™è¯¯
            filtered_matches = [match for match in matches if match.message != 'Possible spelling mistake found.']
            
            if not filtered_matches:
                st.success("æœªå‘ç°è¯­æ³•æˆ–æ‹¼å†™é”™è¯¯ï¼")
            else:
                with col1:
                    st.markdown("### é”™è¯¯è¯¦æƒ…")
                    for i, match in enumerate(filtered_matches):
                        st.markdown(f"""
                        <div style="font-size: 14px; padding: 10px; margin: 5px 0; background-color: #f5f5f5; border-radius: 4px;">
                            <div><span style="font-weight: bold;">é”™è¯¯ç±»å‹</span>: {match.ruleId}</div>
                            <div><span style="font-weight: bold;">é”™è¯¯ä½ç½®</span>: {match.offset}-{match.offset + match.errorLength}</div>
                            <div><span style="font-weight: bold;">é”™è¯¯å†…å®¹</span>: <span style="color: #ff4b4b;">{input_text[match.offset:match.offset + match.errorLength]}</span></div>
                            <div><span style="font-weight: bold;">å»ºè®®ä¿®æ”¹</span>: {match.replacements[0] if match.replacements else 'æ— å»ºè®®'}</div>
                            <div><span style="font-weight: bold;">é”™è¯¯è¯´æ˜</span>: {match.message}</div>
                        </div>
                        """, unsafe_allow_html=True)
                with col2:
                    st.markdown("### é€æ¡ä¿®æ”¹é¢„è§ˆ")
                    for i, match in enumerate(filtered_matches):
                        if match.replacements:
                            modified_segment = (
                                    input_text[:match.offset] +
                                    f"**{match.replacements[0]}**" +
                                    input_text[match.offset + match.errorLength:]
                            )
                            st.markdown(modified_segment)
                            st.markdown('--------------------')

                st.markdown("### æœ€ç»ˆä¿®æ”¹ç»“æœ")
                corrected_text = input_text
                for match in sorted(filtered_matches, key=lambda x: -x.offset):
                    if match.replacements:
                        corrected_text = (
                                corrected_text[:match.offset] +
                                f"**{match.replacements[0]}**" +
                                corrected_text[match.offset + match.errorLength:]
                        )
                st.markdown(corrected_text)

        except Exception as e:
            st.error(f"æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")


def Political_censorship():
    st.session_state.TEX_content = st.session_state.uploaded_file.getvalue().decode(
        'utf-8') if st.session_state.TEX_content is None else st.session_state.TEX_content
    st.session_state.tex_paragraphs = split_tex_into_paragraphs(st.session_state.TEX_content)

    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("TEX æ–‡ä»¶å†…å®¹ï¼ˆåŸå§‹æ®µè½ï¼‰")
        with st.container(height=800, border=False):
            if st.session_state.current_censorship_paragraph_index is not None and not st.session_state.show_all_censorship_paragraphs:
                i = st.session_state.current_censorship_paragraph_index
                paragraph = st.session_state.tex_paragraphs[i]
                with st.container(border=True, height=600):
                    st.markdown(f"**æ®µè½ {i + 1}**")
                    if st.button("â†©ï¸ è¿”å›æ‰€æœ‰æ®µè½", key="back_to_all_censorship_paragraphs"):
                        st.session_state.show_all_censorship_paragraphs = True
                        st.rerun()
                    st.markdown(paragraph)
                    st.session_state.paragraph_to_censor = paragraph
            else:
                for i, paragraph in enumerate(st.session_state.tex_paragraphs):
                    with st.container(border=True, height=300):
                        st.markdown(f"**æ®µè½ {i + 1}**")
                        st.markdown(paragraph)
                        if st.button(f"å®¡æŸ¥è¯¥æ®µè½", key=f"censor_btn_{i}"):
                            st.session_state.current_censorship_paragraph_index = i
                            st.session_state.show_all_censorship_paragraphs = False
                            st.rerun()

    with col2:
        if st.session_state.current_censorship_paragraph_index is not None and st.session_state.paragraph_to_censor:
            st.subheader("æ®µè½æ”¿æ²»å®¡æŸ¥")
            st.markdown(f"**å½“å‰å®¡æŸ¥æ®µè½ {st.session_state.current_censorship_paragraph_index + 1}**")
            st.markdown(st.session_state.paragraph_to_censor)

            st.session_state.censorship_prompt = st.text_area(
                "å®¡æŸ¥è¦æ±‚ (Prompt):",
                value=st.session_state.censorship_prompt,
                height=100,
                key="censorship_prompt_input"
            )

            if st.button("å¼€å§‹æ”¿æ²»å®¡æŸ¥", key="start_censorship_button"):
                with st.spinner("æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ”¿æ²»å®¡æŸ¥..."):
                    system_prompt = """
                    ä½ æ˜¯ä¸€ä½æ”¿æ²»å®¡æŸ¥ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯å¯¹ä¸‹è¿°æ–‡ç« æ®µè½è¿›è¡Œæ”¿æ²»å®¡æŸ¥ï¼Œå¹¶ï¼š
                    1. è¯†åˆ«å¯èƒ½å­˜åœ¨çš„æ”¿æ²»æ•æ„Ÿå†…å®¹ï¼›
                    2. è¯„ä¼°å†…å®¹çš„æ”¿æ²»å€¾å‘æ€§ï¼›
                    3. æŒ‡å‡ºå¯èƒ½è¿åå›½å®¶æ³•å¾‹æ³•è§„çš„å†…å®¹ï¼›
                    4. æä¾›è¯¦ç»†çš„å®¡æŸ¥æ„è§ã€‚
                    è¯·æä¾›å…¨é¢çš„å®¡æŸ¥æŠ¥å‘Šï¼ŒåŒ…æ‹¬å‘ç°çš„é—®é¢˜å’Œå»ºè®®ã€‚
                    """
                    
                    try:
                        model = st.session_state.get("selected_model", "deepseek-chat")
                        content = ""
                        with st.container(height=300):
                            message_placeholder = st.empty()
                            for chunk in st.session_state.Client.chat.completions.create(
                                    model=model,
                                    messages=[
                                        {"role": "system", "content": system_prompt},
                                        {"role": "user", "content": f"{st.session_state.censorship_prompt}\n\næ®µè½å†…å®¹ï¼š{st.session_state.paragraph_to_censor}"}
                                    ],
                                    temperature=0.7,
                                    stream=True
                            ):
                                if chunk.choices and len(chunk.choices) > 0:
                                    delta = chunk.choices[0].delta
                                    if delta and delta.content is not None:
                                        content += delta.content
                                        message_placeholder.markdown(
                                            f"<div style='font-size:16px; margin-top:10px;'>{content}</div>",
                                            unsafe_allow_html=True
                                        )

                        st.session_state.censorship_results[st.session_state.current_censorship_paragraph_index] = content
                        st.session_state.censorship_result = content
                        st.rerun()
                    except Exception as e:
                        st.error(f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")

            if st.session_state.current_censorship_paragraph_index in st.session_state.censorship_results:
                st.markdown("### å®¡æŸ¥ç»“æœ")
                st.markdown(st.session_state.censorship_results[st.session_state.current_censorship_paragraph_index])

                if st.button("è¿”å›æ‰€æœ‰æ®µè½", key="return_to_all_paragraphs_censorship"):
                    st.session_state.show_all_censorship_paragraphs = True
                    st.rerun()

        elif st.session_state.censorship_results:
            st.subheader("æ‰€æœ‰æ®µè½å®¡æŸ¥ç»“æœæ‘˜è¦")
            
            for i, paragraph in enumerate(st.session_state.tex_paragraphs):
                with st.expander(f"æ®µè½ {i + 1} å®¡æŸ¥ç»“æœ", expanded=False):
                    if i in st.session_state.censorship_results:
                        st.markdown(st.session_state.censorship_results[i])
                    else:
                        st.info("è¯¥æ®µè½å°šæœªå®¡æŸ¥")
        
        else:
            st.info("è¯·ä»å·¦ä¾§é€‰æ‹©ä¸€ä¸ªæ®µè½è¿›è¡Œæ”¿æ²»å®¡æŸ¥")


def main():
    initialization()
    st.title("è®ºæ–‡æ¶¦è‰²ä¸å¤„ç†å·¥å…·")

    if st.sidebar.button("æ¸…é™¤æ‰€æœ‰è®°å½•"):
        keys_to_keep = ['previous_page']
        for key in list(st.session_state.keys()):
            if key not in keys_to_keep:
                del st.session_state[key]
        initialization()
        st.rerun()

    with st.sidebar:
        def on_file_change():
            st.session_state.TEX_content = None
            st.session_state.paragraph_to_polish = ""
            st.session_state.polished_paragraph = None
            st.session_state.tex_history = []
            st.session_state.tex_paragraphs = []
            st.session_state.current_polishing_paragraph_index = None
            st.session_state.current_censorship_paragraph_index = None
            st.session_state.show_all_censorship_paragraphs = True
            st.session_state.paragraph_to_censor = ""
            st.session_state.censorship_results = {}
            st.session_state.censorship_result = None
            if 'previous_TEX_content' in st.session_state:
                del st.session_state['previous_TEX_content']

        st.session_state.uploaded_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=['tex'],
            key="file_uploader",
            on_change=on_file_change
        )

        st.sidebar.markdown("### æ¨¡å‹é€‰æ‹©")

        model_names = list(HIGHSPEED_MODEL_MAPPING.keys())
        selected_model_name = st.sidebar.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=model_names,
            index=0
        )
        st.session_state.selected_model = HIGHSPEED_MODEL_MAPPING[selected_model_name]

    tab1, tab2, tab3 = st.tabs(['æ–‡æ®µè¯­æ³•æ£€æŸ¥', 'texæ–‡æ®µæ¶¦è‰²', 'æ”¿æ²»å®¡æŸ¥'])
    with tab1:
        Textual_polishing()

    with tab2:
        if st.session_state.uploaded_file is not None:
            TEX_Polishing()
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")

    with tab3:
        if st.session_state.uploaded_file is not None:
            Political_censorship()
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")


if 'previous_page' not in st.session_state:
    st.session_state.previous_page = 'PaperPolishing'
current_page = 'PaperPolishing'
if current_page != st.session_state.previous_page:
    st.session_state.clear()
    initialization()
    st.session_state.previous_page = current_page
main()
