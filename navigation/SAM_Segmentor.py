# -*- coding: utf-8 -*-
import asyncio

import streamlit as st
from streamlit_image_coordinates import streamlit_image_coordinates
import numpy as np
from pages.SAM2_1.SAM import SAM2Segment
from PIL import Image, ImageDraw
import os
import sys
import io
import cv2
import torch
from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection


async def initialization():
    if "dino" not in st.session_state:
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        model_path = os.path.join(base_dir, "pages/ModelCheckpoint/GroundingDINO-T")
        st.session_state.dino_processor = AutoProcessor.from_pretrained(model_path, use_fast=True)
        st.session_state.dino_model = AutoModelForZeroShotObjectDetection.from_pretrained(model_path).to("cuda")
    if "coordinates" not in st.session_state:
        st.session_state["coordinates"] = None
    if "clicks" not in st.session_state:
        st.session_state.clicks = []
    if "mask_image" not in st.session_state:
        st.session_state.mask_image = None
        st.session_state.combine_image = None
    if "current_image" not in st.session_state:
        st.session_state.current_image = None
        st.session_state.latest_masks = None
    if "current_marker" not in st.session_state:
        st.session_state.current_marker = 1
    if "SAM2" not in st.session_state:
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        sam2_module_path = os.path.join(base_dir, "pages/SAM2_1")
        if sam2_module_path not in sys.path:
            sys.path.append(sam2_module_path)
        sam2_checkpoint = "./pages/SAM2_1/checkpoints/sam2.1_hiera_base_plus.pt"
        model_cfg = "configs/sam2.1/sam2.1_hiera_b+.yaml"
        st.session_state.SAM2 = SAM2Segment(sam2_checkpoint, model_cfg)
        st.session_state.input_point = []
        st.session_state.input_label = []
        st.session_state.box_input = []
    if "box_coordinates" not in st.session_state:
        st.session_state.box_coordinates = None


async def get_rectangle_coords(
        points: tuple[tuple[int, int], tuple[int, int]],
) -> tuple[int, int, int, int]:
    point1, point2 = points
    minx = min(point1[0], point2[0])
    miny = min(point1[1], point2[1])
    maxx = max(point1[0], point2[0])
    maxy = max(point1[1], point2[1])
    return (
        minx,
        miny,
        maxx,
        maxy,
    )


async def resize_image_if_needed(image):
    """
    å¦‚æœå›¾åƒå°ºå¯¸è¿‡å¤§ï¼Œåˆ™ä½¿ç”¨åŒçº¿æ€§æ’å€¼è°ƒæ•´å¤§å°
    """
    if image is None:
        return None

    h, w = image.size[1], image.size[0]
    max_size = 1024

    if h > max_size or w > max_size:
        scale = max_size / max(h, w)
        new_h, new_w = int(h * scale), int(w * scale)

        resized_img = image.resize((new_w, new_h), Image.BILINEAR)

        st.info(f"å›¾åƒå·²ä» {w}x{h} è°ƒæ•´ä¸º {new_w}x{new_h} ä»¥è·å¾—æœ€ä½³æ€§èƒ½")
        return np.array(resized_img)

    return np.array(image)


async def point_inference():
    if st.session_state.current_image is not None:
        st.markdown("### ç‚¹å‡»æ©ç ç”Ÿæˆ")
        if st.session_state.latest_masks is not None:
            masked_image = await st.session_state.SAM2.show_mask(st.session_state.latest_masks,
                                                                 image=st.session_state.current_image)
        else:
            masked_image = st.session_state.current_image
        display_image = await st.session_state.SAM2.show_points(masked_image, st.session_state.clicks)
        try:
            coords = streamlit_image_coordinates(
                display_image,
                key="image",
                height=display_image.shape[0],
                use_column_width=False,
                click_and_drag=False
            )
            if coords and coords != st.session_state.get("last_coord"):
                h, w = st.session_state.current_image.shape[:2]

                actual_x = int(coords["x"])
                actual_y = int(coords["y"])

                actual_x = max(0, min(w - 1, actual_x))
                actual_y = max(0, min(h - 1, actual_y))

                click_data = {
                    "x": actual_x,
                    "y": actual_y,
                    "marker": st.session_state.current_marker
                }
                st.session_state.input_point.append([actual_x, actual_y])
                st.session_state.input_label.append(st.session_state.current_marker)

                masks = await st.session_state.SAM2.point_and_box_inference(st.session_state.current_image,
                                                                            np.array(st.session_state.input_point),
                                                                            np.array(st.session_state.input_label),
                                                                            None)
                st.session_state.latest_masks = (masks[0] * 255)
                st.session_state.masks_image = Image.fromarray(st.session_state.latest_masks.astype(np.uint8))
                st.session_state.combine_image = Image.fromarray(
                    await st.session_state.SAM2.show_mask(
                        st.session_state.latest_masks, image=st.session_state.current_image
                    )
                )
                if click_data not in st.session_state.clicks:
                    st.session_state.clicks.append(click_data)
                    st.session_state.last_coord = coords
                    st.rerun()
        except KeyError as e:
            st.error(f"ç”Ÿæˆåˆ†å‰²å†…å®¹å‡ºé”™: {str(e)}")


async def box_inference():
    if st.session_state.current_image is not None:
        if st.session_state.combine_image:
            masked_image = np.array(st.session_state.combine_image)
        else:
            masked_image = st.session_state.current_image
        img = Image.fromarray(masked_image)
        draw = ImageDraw.Draw(img)

        if st.session_state.box_coordinates:
            coords = await get_rectangle_coords(st.session_state.box_coordinates)
            draw.rectangle(coords, fill=None, outline="red", width=2)

        st.markdown("### æ¡†é€‰ç›®æ ‡åŒºåŸŸ")
        value = streamlit_image_coordinates(
            img,
            key="box_select",
            click_and_drag=True,
            height=img.height,
            use_column_width=False
        )

        if value is not None:
            point1 = (value["x1"], value["y1"])
            point2 = (value["x2"], value["y2"])

            if (point1[0] != point2[0] and point1[1] != point2[1] and
                    st.session_state.box_coordinates != (point1, point2)):
                st.session_state.box_coordinates = (point1, point2)

                box_coords = await get_rectangle_coords(st.session_state.box_coordinates)

                try:
                    with st.spinner("æ­£åœ¨ç”Ÿæˆåˆ†å‰²ç»“æœ..."):
                        st.session_state.box_input.append([box_coords[0], box_coords[1], box_coords[2], box_coords[3]])

                        masks = await st.session_state.SAM2.point_and_box_inference(st.session_state.current_image,
                                                                                    None,
                                                                                    None,
                                                                                    np.array(
                                                                                        st.session_state.box_input))
                        if len(masks.shape) == 4:
                            masks = masks[-1]
                            set_image = np.array(st.session_state.combine_image)
                            st.session_state.latest_masks = (masks[0] * 255)
                            st.session_state.masks_image = Image.fromarray(
                                st.session_state.latest_masks.astype(np.uint8) + np.array(st.session_state.masks_image)
                            )
                        else:
                            set_image = st.session_state.current_image
                            st.session_state.latest_masks = (masks[0] * 255)
                            st.session_state.masks_image = Image.fromarray(
                                st.session_state.latest_masks.astype(np.uint8))
                        st.session_state.combine_image = Image.fromarray(
                            await st.session_state.SAM2.show_mask(
                                st.session_state.latest_masks, image=set_image
                            )
                        )
                        st.rerun()
                except Exception as e:
                    st.error(f"æ¡†é€‰åˆ†å‰²å‡ºé”™: {str(e)}")


async def auto_masks_generator():
    auto_masks = None
    try:
        if st.session_state.current_image is not None:
            st.markdown("### è‡ªåŠ¨æ©ç ç”Ÿæˆ")
            if st.session_state.combine_image is not None:
                st.image(st.session_state.combine_image, use_container_width=True, caption="åˆ†å‰²å›¾åƒ")
            else:
                st.image(st.session_state.current_image, use_container_width=True, caption="åŸå§‹å›¾åƒ")

            if st.button("ç”Ÿæˆå…¨å›¾æ©ç ", help="è‡ªåŠ¨ç”Ÿæˆå…¨å›¾æ‰€æœ‰ç‰©ä½“çš„æ©ç "):
                with st.spinner("æ­£åœ¨ç”Ÿæˆå…¨å›¾æ©ç ..."):
                    auto_masks = await st.session_state.SAM2.auto_mask_genarator(st.session_state.current_image)

            if auto_masks is not None:
                combined_mask = await st.session_state.SAM2.show_masks(st.session_state.current_image, auto_masks)
                st.session_state.masks_image = Image.fromarray(combined_mask)
                blended = cv2.addWeighted(st.session_state.current_image, 0.8,
                                          combined_mask[..., :3], 0.8, 0)
                st.session_state.combine_image = Image.fromarray(blended)
                st.rerun()
    except KeyError as e:
        st.error(f"ç”Ÿæˆåˆ†å‰²å†…å®¹å‡ºé”™: {str(e)}")


async def inference_with_nature_language():
    box_list = []
    if st.session_state.current_image is not None:
        if st.session_state.combine_image:
            masked_image = st.session_state.combine_image
        else:
            masked_image = Image.fromarray(st.session_state.current_image)
        st.image(masked_image)
        if text_labels := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æƒ³è¦åˆ†å‰²çš„åœ°æ–¹ï¼š"):
            if not all(ord(c) < 128 for c in text_labels):
                st.error('ç›®å‰æ¨¡å‹åªæ”¯æŒè‹±æ–‡è¾“å…¥ğŸ¥²')
                return
            text_labels = 'a ' + text_labels + '.'
            text_labels = text_labels.lower()
            inputs = st.session_state.dino_processor(images=masked_image, text=text_labels, return_tensors="pt").to(
                "cuda")
            with st.spinner('å¼€å§‹æ£€æµ‹'):
                with torch.no_grad():
                    outputs = st.session_state.dino_model(**inputs)

                results = st.session_state.dino_processor.post_process_grounded_object_detection(
                    outputs,
                    inputs.input_ids,
                    box_threshold=0.4,
                    text_threshold=0.3,
                    target_sizes=[masked_image.size[::-1]]
                )
                result = results[0]
                for box in result["boxes"]:
                    box = [round(x, 2) for x in box.tolist()]
                    box_list.append(box)
                if not box_list:
                    st.error('æ£€æµ‹å¤±è´¥')
                    return
                else:
                    st.info(f'æ£€æµ‹åˆ°ç›®æ ‡ä½ç½®ï¼š{box_list}')
            with st.spinner('å¼€å§‹åˆ†å‰²'):
                masks = await st.session_state.SAM2.point_and_box_inference(masked_image, input_box=np.array(box_list))
                all_masks = np.zeros(masked_image.size[::-1], dtype=np.float32)
                if len(masks.shape) == 4:
                    for mask in masks:
                        all_masks += mask[0].astype(np.float32)
                else:
                    all_masks = masks[0].astype(np.float32)
                all_masks[all_masks != 0] = 1
                all_masks = (all_masks * 255).astype(np.uint8)
                st.session_state.masks_image = Image.fromarray(all_masks)
                st.session_state.latest_masks = all_masks
                st.session_state.combine_image = Image.fromarray(
                    await st.session_state.SAM2.show_mask(st.session_state.latest_masks, image=np.array(masked_image))
                )
                st.rerun()


async def clear_all():
    st.session_state.clicks = []
    st.session_state.input_point = []
    st.session_state.input_label = []
    st.session_state.latest_masks = None
    st.session_state.combine_image = None
    st.session_state.masks_image = None
    st.session_state.box_coordinates = None


async def main():
    await initialization()
    st.markdown("""
    <h1 style='text-align: center;'>
        SAM2.1äº¤äº’å¼è¯­ä¹‰åˆ†å‰²
    </h1>
    <div style='text-align: center; margin-bottom: 20px;'>
    </div>
    """, unsafe_allow_html=True)

    with st.expander("ä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ğŸŒŸ **ç‚¹è§¦ä¹‹é—´ï¼Œç²¾å‡†åˆ†ç¦»ä¸‡ç‰©** ğŸŒŸ

        **æºé¡¹ç›®åœ°å€**ï¼šhttps://github.com/facebookresearch/sam2

        ğŸ§° **æ“ä½œæŒ‡å—**ï¼š

        1. ä¸Šä¼ éœ€è¦åˆ†å‰²çš„å›¾ç‰‡
        2. é€‰æ‹©æ ‡è®°ç±»å‹ï¼ˆæ­£/è´Ÿæ ‡è®°ï¼‰
        3. ç‚¹å‡»ç›®æ ‡åŒºåŸŸè¿›è¡Œåˆ†å‰²
        4. é€šè¿‡ä¾§è¾¹æ å®æ—¶æŸ¥çœ‹åæ ‡è®°å½•
        5. ä½¿ç”¨å†å²è®°å½•å›æº¯æ“ä½œæ­¥éª¤

        <div style="background: #FCF3CF; padding: 15px; border-radius: 5px; margin-top: 20px;">
            ğŸ”¬ å…¸å‹åº”ç”¨åœºæ™¯ï¼š<br>
            â€¢ äººåƒå‰æ™¯ä¸èƒŒæ™¯æå–<br>
            â€¢ äº§å“æ‘„å½±èƒŒæ™¯åˆ†ç¦»<br>
            â€¢ é¥æ„Ÿå›¾åƒåœ°ç‰©è¯†åˆ«<br>
            æ¯æ¬¡ç‚¹å‡»éƒ½å¸¦æ¥ç²¾å‡†åˆ†å‰²ï¼
        </div>
        """, unsafe_allow_html=True)

    uploaded_file = st.file_uploader("é€‰æ‹©å›¾ç‰‡", type=["jpg", "png", "jpeg"])
    if uploaded_file is not None:
        file_bytes = uploaded_file.getvalue()

        current_file_hash = hash(file_bytes)
        if "previous_file_hash" not in st.session_state or st.session_state.previous_file_hash != current_file_hash:
            await clear_all()
            st.session_state.previous_file_hash = current_file_hash

        st.session_state.current_image = await resize_image_if_needed(Image.open(uploaded_file).convert("RGB"))
    else:
        st.warning('è¯·ä¸Šä¼ å›¾ç‰‡')
        return

    tab1, tab2, tab3, tab4 = st.tabs(
        ['Point inference', 'Box inference', 'Auto Masks Generation', 'Inference with natural language'])
    with tab1:
        await point_inference()

    with tab2:
        await box_inference()

    with tab3:
        await auto_masks_generator()

    with tab4:
        await inference_with_nature_language()

    with st.sidebar:
        marker_type = st.radio(
            "æ ‡è®°ç±»å‹",
            ["æˆ‘æƒ³è¦çš„åŒºåŸŸ(1)", "æˆ‘ä¸æƒ³è¦çš„åŒºåŸŸ(0)"],
            index=0 if st.session_state.current_marker == 1 else 1,
            key="marker_selector"
        )
        st.session_state.current_marker = 1 if "1" in marker_type else 0
        st.markdown("""
            <div class="coordinates-box">
                <h3>ğŸ“Œ åæ ‡ä¿¡æ¯</h3>
                <p>æœ€æ–°åæ ‡ï¼š<br><strong style="color:#4CAF50">({x}, {y})</strong></p>
                <p>å½“å‰æ ‡è®°ï¼š<strong style="color:{color}">[{marker}] {type}</strong></p>
                <div class="history-list">
                    <p>ğŸ“š å†å²è®°å½•ï¼ˆæœ€è¿‘10æ¡ï¼‰ï¼š</p>
                    {history}
                </div>
            </div>
            """.format(
            x=st.session_state.clicks[-1]["x"] if st.session_state.clicks else "N/A",
            y=st.session_state.clicks[-1]["y"] if st.session_state.clicks else "N/A",
            marker=st.session_state.current_marker,
            color="#4CAF50" if st.session_state.current_marker == 1 else "#f44336",
            type=marker_type,
            history="\n".join([
                f'<div class="history-item" style="color: {"#4CAF50" if c["marker"] == 1 else "#f44336"}">'
                f'â†’ ({c["x"]}, {c["y"]}) <small>[{c["marker"]}]</small></div>'
                for c in reversed(st.session_state.clicks[-10:])
            ])
        ), unsafe_allow_html=True)
        if st.button("æ¸…é™¤æ‰€æœ‰è®°å½•"):
            await clear_all()
            st.rerun()

        if st.session_state.combine_image is not None:
            st.markdown("### ä¸‹è½½åˆ†å‰²ç»“æœ")
            col1, col2 = st.columns(2)

            mask_bytes = io.BytesIO()
            st.session_state.masks_image.save(mask_bytes, format='PNG')
            image_bytes = io.BytesIO()
            st.session_state.combine_image.save(image_bytes, format='PNG')

            with col1:
                st.download_button(
                    label="ä¸‹è½½æ©ç ",
                    data=mask_bytes.getvalue(),
                    file_name="mask.png",
                    mime="image/png"
                )

            with col2:
                st.download_button(
                    label="ä¸‹è½½å¸¦æ©ç çš„å›¾åƒ",
                    data=image_bytes.getvalue(),
                    file_name="masked_image.png",
                    mime="image/png"
                )


if 'previous_page' not in st.session_state:
    st.session_state.previous_page = 'SAM2'
current_page = 'SAM2'
if current_page != st.session_state.previous_page:
    st.session_state.clear()
    st.session_state.previous_page = current_page
asyncio.run(main())
