# -*- coding: utf-8 -*-
import os
import warnings

warnings.filterwarnings('ignore')
os.environ['PYTHONWARNINGS'] = 'ignore'

import streamlit as st
from streamlit_image_coordinates import streamlit_image_coordinates
import numpy as np
from pages.SAM3.SAM import SAMSegment
from PIL import Image, ImageDraw
import io
import torch


def initialization():
    if "coordinates" not in st.session_state:
        st.session_state["coordinates"] = None
    if "clicks" not in st.session_state:
        st.session_state.clicks = []
    if "mask_image" not in st.session_state:
        st.session_state.mask_image = None
        st.session_state.combine_image = None
    if "current_image" not in st.session_state:
        st.session_state.current_image = None
        st.session_state.latest_masks = None
    if "current_marker" not in st.session_state:
        st.session_state.current_marker = 1
    if "SAM_model" not in st.session_state:
        st.session_state.SAM_model = SAMSegment()
        st.session_state.input_point = []
        st.session_state.input_label = []
    if "box_coordinates" not in st.session_state:
        st.session_state.box_coordinates = None


def get_rectangle_coords(points: tuple[tuple[int, int], tuple[int, int]],) -> tuple[int, int, int, int]:
    point1, point2 = points
    minx = min(point1[0], point2[0])
    miny = min(point1[1], point2[1])
    maxx = max(point1[0], point2[0])
    maxy = max(point1[1], point2[1])
    return (minx, miny, maxx, maxy)


def resize_image_if_needed(image):
    """
    å¦‚æœå›¾åƒå°ºå¯¸è¿‡å¤§ï¼Œåˆ™ä½¿ç”¨åŒçº¿æ€§æ’å€¼è°ƒæ•´å¤§å°
    """
    if image is None:
        return None

    h, w = image.size[1], image.size[0]
    max_size = 512

    if h > max_size or w > max_size:
        scale = max_size / max(h, w)
        new_h, new_w = int(h * scale), int(w * scale)

        resized_img = image.resize((new_w, new_h), Image.BILINEAR)

        st.info(f"å›¾åƒå·²ä» {w}x{h} è°ƒæ•´ä¸º {new_w}x{new_h} ä»¥è·å¾—æœ€ä½³æ€§èƒ½")
        return np.array(resized_img)

    return np.array(image)


def point_inference():
    with st.sidebar:
        marker_type = st.radio(
            "æ ‡è®°ç±»å‹",
            ["æˆ‘æƒ³è¦çš„åŒºåŸŸ(1)", "æˆ‘ä¸æƒ³è¦çš„åŒºåŸŸ(0)"],
            index=0 if st.session_state.current_marker == 1 else 1,
            key="marker_selector"
        )
        st.session_state.current_marker = 1 if "1" in marker_type else 0
        st.markdown("""
            <div class="coordinates-box">
                <h3>ğŸ“Œ åæ ‡ä¿¡æ¯</h3>
                <p>æœ€æ–°åæ ‡ï¼š<br><strong style="color:#4CAF50">({x}, {y})</strong></p>
                <p>å½“å‰æ ‡è®°ï¼š<strong style="color:{color}">[{marker}] {type}</strong></p>
                <div class="history-list">
                    <p>ğŸ“š å†å²è®°å½•ï¼ˆæœ€è¿‘10æ¡ï¼‰ï¼š</p>
                    {history}
            </div>
            """.format(
            x=st.session_state.clicks[-1]["x"] if st.session_state.clicks else "N/A",
            y=st.session_state.clicks[-1]["y"] if st.session_state.clicks else "N/A",
            marker=st.session_state.current_marker,
            color="#4CAF50" if st.session_state.current_marker == 1 else "#f44336",
            type=marker_type,
            history="\n".join([
                f'<div class="history-item" style="color: {"#4CAF50" if c["marker"] == 1 else "#f44336"}">'
                f'â†’ ({c["x"]}, {c["y"]}) <small>[{c["marker"]}]</small></div>'
                for c in reversed(st.session_state.clicks[-10:])
            ])
        ), unsafe_allow_html=True)
    if st.session_state.current_image is not None:
        st.markdown("### ç‚¹å‡»æ©ç ç”Ÿæˆ")
        if st.session_state.latest_masks is not None:
            masked_image = st.session_state.SAM_model.show_mask(st.session_state.latest_masks,
                                                                image=st.session_state.current_image)
        else:
            masked_image = st.session_state.current_image
        display_image = st.session_state.SAM_model.show_points(masked_image, st.session_state.clicks)
        try:
            coords = streamlit_image_coordinates(
                display_image,
                key="image",
                height=display_image.shape[0],
                use_column_width=False,
                click_and_drag=False
            )
            if coords and coords != st.session_state.get("last_coord"):
                h, w = st.session_state.current_image.shape[:2]

                actual_x = max(0, min(w - 1, int(coords["x"])))
                actual_y = max(0, min(h - 1, int(coords["y"])))

                click_data = {
                    "x": actual_x,
                    "y": actual_y,
                    "marker": st.session_state.current_marker
                }
                st.session_state.input_point.append([actual_x, actual_y])
                st.session_state.input_label.append(st.session_state.current_marker)

                masks = st.session_state.SAM_model.point_and_box_inference(st.session_state.current_image,
                                                                            np.array(st.session_state.input_point),
                                                                            np.array(st.session_state.input_label),
                                                                            None)
                st.session_state.latest_masks = (masks[0] * 255)
                st.session_state.masks_image = Image.fromarray(st.session_state.latest_masks.astype(np.uint8))
                st.session_state.combine_image = Image.fromarray(
                    st.session_state.SAM_model.show_mask(
                        st.session_state.latest_masks, image=st.session_state.current_image
                    )
                )
                if click_data not in st.session_state.clicks:
                    st.session_state.clicks.append(click_data)
                    st.session_state.last_coord = coords
                    st.rerun()
        except KeyError as e:
            st.error(f"ç”Ÿæˆåˆ†å‰²å†…å®¹å‡ºé”™: {str(e)}")


def box_inference():
    if st.session_state.current_image is not None:
        masked_image = np.array(st.session_state.combine_image) if st.session_state.combine_image else st.session_state.current_image
        img = Image.fromarray(masked_image)
        draw = ImageDraw.Draw(img)

        if st.session_state.box_coordinates:
            coords = get_rectangle_coords(st.session_state.box_coordinates)
            draw.rectangle(coords, fill=None, outline="red", width=2)

            if st.session_state.get('last_box_coordinates', None) != st.session_state.box_coordinates:
                st.session_state.last_box_coordinates = st.session_state.box_coordinates
                box_coords = get_rectangle_coords(st.session_state.box_coordinates)
                try:
                    with st.spinner("æ­£åœ¨ç”Ÿæˆåˆ†å‰²ç»“æœ..."):
                        box_input = [box_coords[0], box_coords[1], box_coords[2], box_coords[3]]
                        masks = st.session_state.SAM_model.point_and_box_inference(
                            st.session_state.current_image, None, None, np.array(box_input))
                        if len(masks.shape) == 4:
                            masks = masks[-1]
                            set_image = np.array(st.session_state.combine_image)
                            st.session_state.latest_masks = (masks[0] * 255)
                            st.session_state.masks_image = Image.fromarray(
                                st.session_state.latest_masks.astype(np.uint8) + np.array(st.session_state.masks_image)
                            )
                        else:
                            set_image = st.session_state.current_image
                            st.session_state.latest_masks = (masks[0] * 255)
                            st.session_state.masks_image = Image.fromarray(
                                st.session_state.latest_masks.astype(np.uint8))
                        st.session_state.combine_image = Image.fromarray(
                            st.session_state.SAM_model.show_mask(st.session_state.latest_masks, image=set_image))
                        st.rerun()
                except Exception as e:
                    st.error(f"æ¡†é€‰åˆ†å‰²å‡ºé”™: {str(e)}")

        st.markdown("### æ¡†é€‰ç›®æ ‡åŒºåŸŸ")
        value = streamlit_image_coordinates(
            img,
            key="box_select",
            click_and_drag=True,
            height=img.height,
        )

        if value:
            point1 = (value["x1"], value["y1"])
            point2 = (value["x2"], value["y2"])

            if point1[0] != point2[0] and point1[1] != point2[1] and st.session_state.box_coordinates != (point1, point2):
                st.session_state.box_coordinates = (point1, point2)
                st.rerun()


def inference_with_nature_language():
    with st.sidebar:
        confidence = st.slider("confidence", 0.0, 1.0, 0.3, 0.1, help="æ§åˆ¶è¿‡æ»¤ä¸¥æ ¼åº¦ã€‚å€¼è¶Šé«˜è¿‡æ»¤è¶Šä¸¥æ ¼")
    if st.session_state.current_image is not None:
        masked_image = st.session_state.combine_image if st.session_state.combine_image else Image.fromarray(st.session_state.current_image)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### åŸå§‹å›¾ç‰‡")
            st.image(Image.fromarray(st.session_state.current_image), use_container_width=True)
        with col2:
            st.markdown("#### åˆ†å‰²ç»“æœ")
            if st.session_state.combine_image is not None:
                st.image(st.session_state.combine_image, use_container_width=True)
            else:
                st.info("ç­‰å¾…åˆ†å‰²ç»“æœ...")
        
        if text_labels := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æƒ³è¦åˆ†å‰²çš„åœ°æ–¹ï¼š"):
            masks = st.session_state.SAM_model.concept_inference(masked_image, text_labels, confidence)
            if masks.shape[0] == 0:
                st.error('æ²¡æœ‰æ£€æµ‹å‡ºæ¥å“¦ï¼Œè¯·é‡è¯•')
            else:
                masks = masks.to('cpu')
                all_masks = torch.zeros(masked_image.size[::-1])
                for mask in masks:
                    all_masks += mask[0]
                all_masks[all_masks != 0] = 1
                all_masks = np.array(all_masks)
                all_masks = (all_masks * 255).astype(np.uint8)
                st.session_state.masks_image = Image.fromarray(all_masks)
                st.session_state.latest_masks = all_masks
                st.session_state.combine_image = Image.fromarray(
                    st.session_state.SAM_model.show_mask(st.session_state.latest_masks, image=st.session_state.current_image)
                )
                st.rerun()


def clear_all():
    st.session_state.clicks = []
    st.session_state.input_point = []
    st.session_state.input_label = []
    st.session_state.latest_masks = None
    st.session_state.combine_image = None
    st.session_state.masks_image = None
    st.session_state.box_coordinates = None


def main():
    initialization()
    st.markdown("""
    <h1 style='text-align: center;'>
        SAM3äº¤äº’å¼è¯­ä¹‰åˆ†å‰²
    </h1>
    <div style='text-align: center; margin-bottom: 20px;'>
    </div>
    """, unsafe_allow_html=True)

    with st.expander("ä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ğŸŒŸ **ç‚¹è§¦ä¹‹é—´ï¼Œç²¾å‡†åˆ†ç¦»ä¸‡ç‰©** ğŸŒŸ

        **æºé¡¹ç›®åœ°å€**ï¼šhttps://github.com/facebookresearch/sam3

        ğŸ§° **æ“ä½œæŒ‡å—**ï¼š

        1. ä¸Šä¼ éœ€è¦åˆ†å‰²çš„å›¾ç‰‡
        2. é€‰æ‹©æ ‡è®°ç±»å‹ï¼ˆæ­£/è´Ÿæ ‡è®°ï¼‰
        3. ç‚¹å‡»ç›®æ ‡åŒºåŸŸè¿›è¡Œåˆ†å‰²
        4. é€šè¿‡ä¾§è¾¹æ å®æ—¶æŸ¥çœ‹åæ ‡è®°å½•
        5. ä½¿ç”¨å†å²è®°å½•å›æº¯æ“ä½œæ­¥éª¤

        ğŸ”¬ å…¸å‹åº”ç”¨åœºæ™¯ï¼š<br>
        â€¢ äººåƒå‰æ™¯ä¸èƒŒæ™¯æå–<br>
        â€¢ äº§å“æ‘„å½±èƒŒæ™¯åˆ†ç¦»<br>
        â€¢ é¥æ„Ÿå›¾åƒåœ°ç‰©è¯†åˆ«<br>
        æ¯æ¬¡ç‚¹å‡»éƒ½å¸¦æ¥ç²¾å‡†åˆ†å‰²ï¼
        """, unsafe_allow_html=True)

    uploaded_file = st.file_uploader("é€‰æ‹©å›¾ç‰‡", type=["jpg", "png", "jpeg", "webp"])
    if uploaded_file is not None:
        file_bytes = uploaded_file.getvalue()

        current_file_hash = hash(file_bytes)
        if "previous_file_hash" not in st.session_state or st.session_state.previous_file_hash != current_file_hash:
            clear_all()
            st.session_state.previous_file_hash = current_file_hash

        st.session_state.current_image = resize_image_if_needed(Image.open(uploaded_file).convert("RGB"))
    else:
        st.warning('è¯·ä¸Šä¼ å›¾ç‰‡')
        return

    tab1, tab2, tab3 = st.tabs(
        ['Inference with natural language', 'Point inference', 'Box inference'])
    with tab1:
        inference_with_nature_language()
    with tab2:
        point_inference()
    with tab3:
        box_inference()

    with st.sidebar:
        if st.button("æ¸…é™¤æ‰€æœ‰è®°å½•"):
            clear_all()
            st.rerun()

        if st.session_state.combine_image is not None:
            st.markdown("### ä¸‹è½½åˆ†å‰²ç»“æœ")
            col1, col2 = st.columns(2)

            mask_bytes = io.BytesIO()
            st.session_state.masks_image.save(mask_bytes, format='PNG')
            image_bytes = io.BytesIO()
            st.session_state.combine_image.save(image_bytes, format='PNG')

            with col1:
                st.download_button(
                    label="ä¸‹è½½æ©ç ",
                    data=mask_bytes.getvalue(),
                    file_name="mask.png",
                    mime="image/png"
                )

            with col2:
                st.download_button(
                    label="ä¸‹è½½å¸¦æ©ç çš„å›¾åƒ",
                    data=image_bytes.getvalue(),
                    file_name="masked_image.png",
                    mime="image/png"
                )


if 'previous_page' not in st.session_state:
    st.session_state.previous_page = 'SAM3'
current_page = 'SAM3'
if current_page != st.session_state.previous_page:
    st.session_state.clear()
    st.session_state.previous_page = current_page
main()
