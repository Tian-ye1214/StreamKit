# -*- coding: utf-8 -*-
import streamlit as st
from pages.Functions.BackendInteraction import BackendInteractionLogic
from pages.Functions.Constants import HIGHSPEED_MODEL_MAPPING, VISIONMODAL_MAPPING
import asyncio

st.set_page_config(
    page_title="Chat With AI",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="auto",
)


async def main():
    backend = BackendInteractionLogic()
    backend.initialize_session_state()
    st.markdown("""
    <h1 style='text-align: center;'>
        Chat With AI
    </h1>
    <div style='text-align: center; margin-bottom: 20px;'>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        await asyncio.gather(backend.user_interaction(), backend.start_new_conversation()
                             , backend.parameter_configuration())
        st.markdown("""
        <h3 style='text-align: center;'>
            æ¨¡å‹é…ç½®
        </h3>
        """, unsafe_allow_html=True)
        sections = st.radio("å¯¹è¯æ¨¡å¼",
                            ["æ–‡æœ¬å¯¹è¯", "è§†è§‰å¯¹è¯"],
                            index=0,
                            )
        if sections == 'æ–‡æœ¬å¯¹è¯':
            model_display = st.selectbox("é€‰æ‹©æ¨¡å‹", list(HIGHSPEED_MODEL_MAPPING.keys()), index=0, help="é€‰æ‹©æ¨¡å‹")
            st.session_state.model = HIGHSPEED_MODEL_MAPPING[model_display]
        else:
            model_display = st.selectbox("é€‰æ‹©æ¨¡å‹", list(VISIONMODAL_MAPPING.keys()), index=0, help="é€‰æ‹©æ¨¡å‹")
            st.session_state.model = VISIONMODAL_MAPPING[model_display]

        st.markdown("è”ç³»ä½œè€…")
        st.markdown(f"""
        ğŸ“§ [Z1092228927@outlook.com](mailto:Z1092228927@outlook.com)<br>
        ğŸ± [Tian-ye1214](https://github.com/Tian-ye1214)
        """, unsafe_allow_html=True)

    if sections == 'è§†è§‰å¯¹è¯':
        backend.image_upload()

    for message in st.session_state.chat_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜ï¼š"):
        await asyncio.gather(backend.user_input(prompt), backend.search_interaction())

        with st.chat_message("assistant"):
            try:
                with st.spinner('æ¨¡å‹æ€è€ƒä¸­'):
                    await asyncio.gather(backend.ai_generation(sections))
            except Exception as e:
                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}")


if 'previous_page' not in st.session_state:
    st.session_state.previous_page = 'chat'
current_page = 'chat'
if current_page != st.session_state.previous_page:
    st.session_state.clear()
    st.session_state.previous_page = current_page

asyncio.run(main())
