import os
import streamlit as st
from openai import OpenAI
from pages.Functions.ExtractFileContents import extract_text, encode_image_to_base64
from pages.Functions.UserLogManager import UserLogManager
from pages.Functions.Prompt import (
    generate_document_prompt,
    generate_search_prompt,
    generate_combined_prompt
)
from pages.Functions.Constants import MODEL_MAPPING, MULTIMODAL_MODELS, SEARCH_METHODS, REASON_MODELS

st.set_page_config(
    page_title="Chat With AI",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)


def initialize_session_state():
    if "api_key" not in st.session_state:
        st.session_state.api_key = 'sk-wxmqrirjoqrahuuyxbornwawplaobdlpxjefkzpfgiackdmu'
    if "base_url" not in st.session_state:
        st.session_state.base_url = os.getenv('OPENAI_BASE_URL', "https://api.siliconflow.cn/v1/")

    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    if len(st.session_state.chat_messages) > 40:
        st.session_state.chat_messages = st.session_state.chat_messages[-40:]

    if "openai_client" not in st.session_state:
        st.session_state.openai_client = None
    if "system_prompt" not in st.session_state:
        st.session_state.system_prompt = ""

    if "file_content" not in st.session_state:
        st.session_state.file_content = None

    if "current_user" not in st.session_state:
        st.session_state.current_user = None
    if "log_manager" not in st.session_state:
        st.session_state.log_manager = UserLogManager()

    if "current_log_filename" not in st.session_state:
        st.session_state.current_log_filename = None

    if "search_mode" not in st.session_state:
        st.session_state.search_mode = None
    if "search_result" not in st.session_state:
        st.session_state.search_result = None


def main():
    initialize_session_state()

    st.markdown("""
    <h1 style='text-align: center;'>
        Chat With AI
    </h1>
    <div style='text-align: center; margin-bottom: 20px;'>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.markdown("### ç”¨æˆ·ç™»å½•")
        username = st.text_input("è¯·è¾“å…¥ç”¨æˆ·å", key="username_input")

        if st.button("ç™»å½•/æ³¨å†Œ"):
            if username.strip() == "":
                st.error("ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
            else:
                st.session_state.current_user = username
                if not st.session_state.log_manager.check_user_exists(username):
                    st.success(f"æ¬¢è¿ {'æ–°ç”¨æˆ·'} ")
                    st.session_state.log_manager.user_register(username)

                else:
                    st.success(f"æ¬¢è¿ {'å›æ¥'} {username}ï¼")

        if st.session_state.current_user:
            st.markdown(f"å½“å‰ç”¨æˆ·ï¼š**{st.session_state.current_user}**")
            history_logs = st.session_state.log_manager.get_user_history(st.session_state.current_user)

            if len(history_logs) > 0:
                st.markdown("### å†å²å¯¹è¯")
                selected_log = st.selectbox("é€‰æ‹©å†å²è®°å½•", history_logs)
                col1, col2, col3 = st.columns([1, 1, 1])
                with col1:
                    if st.button("åŠ è½½è®°å½•", help="è¯»å–å¹¶åŠ è½½é€‰ä¸­çš„å¯¹è¯è®°å½•"):
                        chat_log = st.session_state.log_manager.load_chat_log(
                            st.session_state.current_user,
                            selected_log
                        )
                        st.session_state.chat_messages = chat_log["messages"]
                        st.session_state.current_log_filename = selected_log + '.json'
                        st.rerun()

                with col2:
                    if st.button("åˆ é™¤è®°å½•", help="åˆ é™¤é€‰ä¸­çš„å¯¹è¯è®°å½•"):
                        st.session_state.delete_target = selected_log
                
                with col3:
                    json_data = st.session_state.log_manager.get_log_filepath(
                        st.session_state.current_user,
                        selected_log + '.json'
                    )
                    with open(json_data, "rb") as f:
                        st.download_button(
                            label="ä¸‹è½½è®°å½•",
                            data=f,
                            file_name=selected_log + '.json',
                            mime="application/json",
                            help="ä¸‹è½½é€‰ä¸­çš„å¯¹è¯è®°å½•åˆ°æœ¬åœ°"
                        )

            if 'delete_target' in st.session_state:
                st.warning(f"ç¡®è®¤è¦æ°¸ä¹…åˆ é™¤è®°å½•[{st.session_state.delete_target}]å—ï¼Ÿè¯¥è¿‡ç¨‹ä¸å¯é€†ï¼")
                if st.button("ç¡®è®¤åˆ é™¤", type="primary"):
                    try:
                        success = st.session_state.log_manager.delete_chat_log(
                            st.session_state.current_user,
                            st.session_state.delete_target + '.json'
                        )
                        if success:
                            st.success("è®°å½•å·²æ°¸ä¹…åˆ é™¤")
                            st.session_state.current_log_filename = None
                            st.session_state.chat_messages = []
                            del st.session_state.delete_target
                            st.rerun()
                        else:
                            st.error("åˆ é™¤å¤±è´¥ï¼šæ–‡ä»¶ä¸å­˜åœ¨")
                    except Exception as e:
                        st.error(f"åˆ é™¤å¤±è´¥ï¼š{str(e)}")
                if st.button("å–æ¶ˆåˆ é™¤"):
                    del st.session_state.delete_target
                    st.rerun()

        else:
            st.info("è¯¥ç”¨æˆ·æš‚æ— å†å²å¯¹è¯è®°å½•")

        st.markdown("""
        <h3 style='text-align: center;'>
            æ¨¡å‹é…ç½®
        </h3>
        """, unsafe_allow_html=True)
        st.session_state.openai_client = OpenAI(api_key=st.session_state.api_key, base_url=st.session_state.base_url)

        model_display = st.selectbox("é€‰æ‹©æ¨¡å‹", list(MODEL_MAPPING.keys()), index=1, help="é€‰æ‹©æ¨¡å‹")
        model = MODEL_MAPPING[model_display]
        if model not in REASON_MODELS:
            st.session_state.system_prompt = "You are a helpful assistant."

        if st.button("å¼€å¯æ–°å¯¹è¯", help="å¼€å¯æ–°å¯¹è¯å°†æ¸…ç©ºå½“å‰å¯¹è¯è®°å½•"):
            st.session_state.current_log_filename = None
            st.session_state.chat_messages = []
            st.success("å·²æˆåŠŸå¼€å¯æ–°çš„å¯¹è¯")
            st.rerun()

        with st.expander("å¯¹è¯å‚æ•°", expanded=False):
            col1, col2 = st.columns(2)

            with col1:
                temperature = st.slider("Temperature", 0.0, 2.0, 0.6, 0.1,
                                        help="æ§åˆ¶å“åº”çš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºå“åº”è¶Šéšæœº")
                presence_penalty = st.slider("Presence Penalty", -2.0, 2.0, 0.0, 0.1,
                                             help="æ­£å€¼ä¼šæ ¹æ®æ–°ä¸»é¢˜æƒ©ç½šæ¨¡å‹ï¼Œè´Ÿå€¼ä¼šä½¿æ¨¡å‹æ›´å€¾å‘äºé‡å¤å†…å®¹")
                max_tokens = st.number_input("Max Tokens",
                                             min_value=1,
                                             max_value=8192,
                                             value=4096,
                                             help="ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦")

            with col2:
                top_p = st.slider("Top P", 0.0, 1.0, 0.9, 0.1,
                                  help="æ§åˆ¶è¯æ±‡é€‰æ‹©çš„å¤šæ ·æ€§")
                frequency_penalty = st.slider("Frequency Penalty", -2.0, 2.0, 0.0, 0.1,
                                              help="æ­£å€¼ä¼šæ ¹æ®æ–‡æœ¬é¢‘ç‡æƒ©ç½šæ¨¡å‹ï¼Œè´Ÿå€¼é¼“åŠ±é‡å¤")
                stream = st.toggle("æµå¼è¾“å‡º", value=True,
                                   help="å¯ç”¨æµå¼è¾“å‡ºå¯ä»¥å®æ—¶çœ‹åˆ°ç”Ÿæˆç»“æœ")

        with st.expander("Promptè®¾ç½®", expanded=False):
            system_prompt = st.text_area("System Prompt",
                                         value=st.session_state.system_prompt,
                                         help="è®¾ç½®AIåŠ©æ‰‹çš„è§’è‰²å’Œè¡Œä¸º")
            if st.button("æ›´æ–°System Prompt"):
                st.session_state.system_prompt = system_prompt
                st.success("System Promptå·²æ›´æ–°")

        with st.expander("æ–‡ä»¶ä¸Šä¼ ", expanded=False):
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ æ–‡ä»¶(æ”¯æŒPDFã€Wordã€TxTã€CSV)",
                type=["pdf", "docx", "txt", "csv"],
                accept_multiple_files=False
            )

            if uploaded_file:
                try:
                    file_content = extract_text(uploaded_file)
                    if file_content:
                        st.session_state.file_content = file_content
                        st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
                        st.text_area("æ–‡ä»¶å†…å®¹é¢„è§ˆ",
                                     value=file_content[:200] + "...",
                                     height=150)
                except Exception as e:
                    st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

            if st.button("æ¸…é™¤ä¸Šä¼ çš„æ–‡ä»¶"):
                st.session_state.file_content = None
                st.success("æ–‡ä»¶å·²æ¸…é™¤")
                st.rerun()

        with st.expander("ç½‘ç»œæœç´¢", expanded=False):
            search_mode = st.selectbox(
                "é€‰æ‹©æœç´¢æ¨¡å¼",
                ["å…³é—­æœç´¢", "æ–‡æœ¬æœç´¢", "æ–°é—»æœç´¢", "å›¾ç‰‡æœç´¢", "è§†é¢‘æœç´¢"],
                index=0
            )
            st.session_state.search_mode = None if search_mode == "å…³é—­æœç´¢" else search_mode

            if st.session_state.search_mode:
                st.session_state.search_max_results = st.number_input("æœ€å¤§ç»“æœæ•°",
                                                                      min_value=1,
                                                                      max_value=5,
                                                                      value=3,
                                                                      help="è®¾ç½®æœ€å¤§è¿”å›çš„æœç´¢ç»“æœæ•°é‡")

        if model in MULTIMODAL_MODELS:
            with st.expander("å›¾ç‰‡ä¸Šä¼ ", expanded=False):
                uploaded_image = st.file_uploader(
                    "ä¸Šä¼ å›¾ç‰‡",
                    type=["jpg", "jpeg", "png"]
                )
                if uploaded_image:
                    st.image(uploaded_image, caption="å›¾ç‰‡é¢„è§ˆ", use_container_width=True)

        with st.expander("Temperatureå‚æ•°ä½¿ç”¨æ¨è", expanded=False):
            st.markdown("""
            | åœºæ™¯ | æ¸©åº¦ |
            |------|------|
            | ä»£ç ç”Ÿæˆ/æ•°å­¦è§£é¢˜ | 0.0 |
            | æ•°æ®æŠ½å–/åˆ†æ/æ¨ç† | 0.6 |
            | é€šç”¨å¯¹è¯ | 0.8 |
            | ç¿»è¯‘ | 1.0 |
            | åˆ›æ„å†™ä½œ/è¯—æ­Œåˆ›ä½œ | 1.3 |
            """)

    # åœ¨æ˜¾ç¤ºå†å²æ¶ˆæ¯å‰æ·»åŠ åŠ¨æ€è®¡æ•°å™¨
    msg_counter = st.empty()
    msg_counter.markdown(f"""
    <div style='text-align: center; margin: 10px 0; font-size:14px;'>
        å½“å‰å¯¹è¯æ¶ˆæ¯æ•°ï¼š<span style='color: #ff4b4b; font-weight:bold;'>{len(st.session_state.chat_messages)}</span>/40
    </div>
    """, unsafe_allow_html=True)

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for message in st.session_state.chat_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜ï¼š"):
        current_prompt = {"role": "user", "content": prompt}
        st.session_state.chat_messages.append(current_prompt)
        msg_counter.markdown(f"""
        <div style='text-align: center; margin: 10px 0; font-size:14px;'>
            å½“å‰å¯¹è¯æ¶ˆæ¯æ•°ï¼š<span style='color: #ff4b4b; font-weight:bold;'>{len(st.session_state.chat_messages)}</span>/40
        </div>
        """, unsafe_allow_html=True)

        with st.chat_message("user"):
            st.markdown(prompt)

        if st.session_state.search_mode in SEARCH_METHODS:
            try:
                from pages.Functions.WebSearch import WebSearch
                search = WebSearch(query=prompt, max_results=st.session_state.search_max_results)
                method = getattr(search, SEARCH_METHODS[st.session_state.search_mode])
                st.session_state.search_result = method()

                # æ˜¾ç¤ºæœç´¢ç»“æœ
                with st.chat_message("assistant"):
                    st.markdown("ğŸ” æœç´¢åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š")
                    for i, result in enumerate(st.session_state.search_result):
                        st.markdown(f"{i + 1}. [{result['title']}]({result['href']})")
                        st.caption(result['body'][:min(len(result['body']), 100)] + "...")
            except Exception as e:
                st.error(f"æ²¡æœ‰æ£€ç´¢åˆ°ç­”æ¡ˆå“¦ï¼Œé”™è¯¯ä¿¡æ¯:{e}")
                st.session_state.search_result = None

        # AIå“åº”
        with st.chat_message("assistant"):
            try:
                def get_system_prompt():
                    if st.session_state.file_content and st.session_state.search_result:
                        return generate_combined_prompt(
                            st.session_state.file_content,
                            st.session_state.search_result
                        )
                    if st.session_state.file_content:
                        return generate_document_prompt(st.session_state.file_content)
                    if st.session_state.search_result:
                        return generate_search_prompt(st.session_state.search_result)
                    return st.session_state.system_prompt

                messages = [{"role": "system", "content": get_system_prompt()}]

                if model in MULTIMODAL_MODELS and uploaded_image:
                    base64_image = encode_image_to_base64(uploaded_image)
                    if base64_image:
                        messages.append({
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}},
                            ],
                        })
                    else:
                        messages.append({"role": "user", "content": prompt})
                else:
                    messages.append({"role": "user", "content": prompt})

                messages.extend([{"role": m["role"], "content": m["content"]}
                                 for m in st.session_state.chat_messages])

                if stream:
                    reason_placeholder = st.empty()
                    message_placeholder = st.empty()
                    content = ""
                    reasoning_content = ""

                    for chunk in st.session_state.openai_client.chat.completions.create(
                            model=model,
                            messages=messages,
                            temperature=temperature,
                            top_p=top_p,
                            presence_penalty=presence_penalty,
                            frequency_penalty=frequency_penalty,
                            max_tokens=max_tokens,
                            stream=True
                    ):
                        if chunk.choices and len(chunk.choices) > 0:
                            delta = chunk.choices[0].delta
                            if getattr(delta, 'reasoning_content', None):
                                reasoning_content += delta.reasoning_content
                                reason_placeholder.markdown(
                                    f"<div style='background:#f0f0f0; border-radius:5px; padding:10px; margin-bottom:10px; font-size:14px;'>"
                                    f"ğŸ¤” {reasoning_content}</div>",
                                    unsafe_allow_html=True
                                )
                            if delta and delta.content is not None:
                                content += delta.content
                                message_placeholder.markdown(
                                    f"<div style='font-size:16px; margin-top:10px;'>{content}</div>",
                                    unsafe_allow_html=True
                                )
                    assistant_response = content
                else:
                    response = st.session_state.openai_client.chat.completions.create(
                        model=model,
                        messages=messages,
                        temperature=temperature,
                        top_p=top_p,
                        presence_penalty=presence_penalty,
                        frequency_penalty=frequency_penalty,
                        max_tokens=max_tokens,
                        stream=False
                    )
                    reasoning_content = getattr(response.choices[0].message, 'reasoning_content', '')
                    assistant_response = response.choices[0].message.content

                    if reasoning_content:
                        st.markdown(
                            f"<div style='background:#f0f0f0; border-radius:5px; padding:10px; margin-bottom:10px; font-size:14px;'>"
                            f"ğŸ¤” {reasoning_content}</div>",
                            unsafe_allow_html=True
                        )
                    st.markdown(assistant_response)
                current_response = {"role": "assistant", "content": assistant_response}
                st.session_state.chat_messages.append(current_response)

                if len(st.session_state.chat_messages) > 40:
                    st.session_state.chat_messages = st.session_state.chat_messages[-40:]

                if st.session_state.current_user:
                    new_filename = st.session_state.log_manager.save_chat_log(
                        st.session_state.current_user,
                        [current_prompt, current_response],
                        log_filename=st.session_state.current_log_filename
                    )
                    if st.session_state.current_log_filename is None:
                        st.session_state.current_log_filename = new_filename

            except Exception as e:
                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}")


if __name__ == "__main__":
    main()
